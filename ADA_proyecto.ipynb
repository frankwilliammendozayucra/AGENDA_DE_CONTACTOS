{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankwilliammendozayucra/AGENDA_DE_CONTACTOS/blob/main/ADA_proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n-UQLZ4ovFdE"
      },
      "outputs": [],
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from typing import Literal\n",
        "import time\n",
        "from collections import deque\n",
        "import traceback\n",
        "import heapq\n",
        "# Configuraci√≥n para visualizaci√≥n\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8zwvcUGmvOvj"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ALGORITMOS DE ORDENAMIENTO\n",
        "# ========================================\n",
        "\n",
        "class SortingAlgorithms:\n",
        "    \"\"\"Clase que implementa 10 algoritmos de ordenamiento\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def bubble_sort(df, column, ascending=True):\n",
        "        \"\"\"Bubble Sort - O(n¬≤)\"\"\"\n",
        "        df_copy = df.copy().reset_index(drop=True)\n",
        "        n = len(df_copy)\n",
        "        for i in range(n):\n",
        "            for j in range(0, n-i-1):\n",
        "                if ascending:\n",
        "                    if df_copy.loc[j, column] > df_copy.loc[j+1, column]:\n",
        "                        df_copy.iloc[j], df_copy.iloc[j+1] = df_copy.iloc[j+1].copy(), df_copy.iloc[j].copy()\n",
        "                else: # Descending\n",
        "                    if df_copy.loc[j, column] < df_copy.loc[j+1, column]:\n",
        "                        df_copy.iloc[j], df_copy.iloc[j+1] = df_copy.iloc[j+1].copy(), df_copy.iloc[j].copy()\n",
        "        return df_copy\n",
        "\n",
        "    @staticmethod\n",
        "    def selection_sort(df, column, ascending=True):\n",
        "        \"\"\"Selection Sort - O(n¬≤)\"\"\"\n",
        "        df_copy = df.copy().reset_index(drop=True)\n",
        "        n = len(df_copy)\n",
        "        for i in range(n):\n",
        "            idx = i\n",
        "            for j in range(i+1, n):\n",
        "                if ascending:\n",
        "                    if df_copy.loc[j, column] < df_copy.loc[idx, column]:\n",
        "                        idx = j\n",
        "                else: # Descending\n",
        "                    if df_copy.loc[j, column] > df_copy.loc[idx, column]:\n",
        "                        idx = j\n",
        "            df_copy.iloc[i], df_copy.iloc[idx] = df_copy.iloc[idx].copy(), df_copy.iloc[i].copy()\n",
        "        return df_copy\n",
        "\n",
        "    @staticmethod\n",
        "    def insertion_sort(df, column, ascending=True):\n",
        "        \"\"\"Insertion Sort - O(n¬≤)\"\"\"\n",
        "        df_copy = df.copy().reset_index(drop=True)\n",
        "        for i in range(1, len(df_copy)):\n",
        "            key_row = df_copy.iloc[i].copy()\n",
        "            key_value = df_copy.loc[i, column]\n",
        "            j = i - 1\n",
        "            if ascending:\n",
        "                while j >= 0 and df_copy.loc[j, column] > key_value:\n",
        "                    df_copy.iloc[j + 1] = df_copy.iloc[j].copy()\n",
        "                    j -= 1\n",
        "            else: # Descending\n",
        "                while j >= 0 and df_copy.loc[j, column] < key_value:\n",
        "                    df_copy.iloc[j + 1] = df_copy.iloc[j].copy()\n",
        "                    j -= 1\n",
        "            df_copy.iloc[j + 1] = key_row\n",
        "        return df_copy\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_sort(df, column, ascending=True):\n",
        "        \"\"\"Merge Sort - O(n log n)\"\"\"\n",
        "        if len(df) <= 1:\n",
        "            return df.copy()\n",
        "\n",
        "        mid = len(df) // 2\n",
        "        left_half = df.iloc[:mid]\n",
        "        right_half = df.iloc[mid:]\n",
        "\n",
        "        left = SortingAlgorithms.merge_sort(left_half, column, ascending)\n",
        "        right = SortingAlgorithms.merge_sort(right_half, column, ascending)\n",
        "\n",
        "        return SortingAlgorithms._merge(left, right, column, ascending)\n",
        "\n",
        "    @staticmethod\n",
        "    def _merge(left, right, column, ascending):\n",
        "        \"\"\"Funci√≥n auxiliar para merge sort\"\"\"\n",
        "        result = []\n",
        "        i = j = 0\n",
        "        left_records = left.to_dict('records')\n",
        "        right_records = right.to_dict('records')\n",
        "\n",
        "        while i < len(left_records) and j < len(right_records):\n",
        "            if ascending:\n",
        "                if left_records[i][column] <= right_records[j][column]:\n",
        "                    result.append(left_records[i])\n",
        "                    i += 1\n",
        "                else:\n",
        "                    result.append(right_records[j])\n",
        "                    j += 1\n",
        "            else: # Descending\n",
        "                if left_records[i][column] >= right_records[j][column]:\n",
        "                    result.append(left_records[i])\n",
        "                    i += 1\n",
        "                else:\n",
        "                    result.append(right_records[j])\n",
        "                    j += 1\n",
        "\n",
        "        result.extend(left_records[i:])\n",
        "        result.extend(right_records[j:])\n",
        "\n",
        "        return pd.DataFrame(result)\n",
        "\n",
        "    @staticmethod\n",
        "    def quick_sort(df, column, ascending=True):\n",
        "        \"\"\"Quick Sort - O(n log n) promedio\"\"\"\n",
        "        if len(df) <= 1:\n",
        "            return df.copy()\n",
        "\n",
        "        pivot_row = df.iloc[len(df) // 2]\n",
        "        pivot_value = pivot_row[column]\n",
        "\n",
        "        if ascending:\n",
        "            left = df[df[column] < pivot_value]\n",
        "            middle = df[df[column] == pivot_value]\n",
        "            right = df[df[column] > pivot_value]\n",
        "        else: # Descending\n",
        "            left = df[df[column] > pivot_value]\n",
        "            middle = df[df[column] == pivot_value]\n",
        "            right = df[df[column] < pivot_value]\n",
        "\n",
        "        return pd.concat([\n",
        "            SortingAlgorithms.quick_sort(left, column, ascending),\n",
        "            middle,\n",
        "            SortingAlgorithms.quick_sort(right, column, ascending)\n",
        "        ]).reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def heap_sort(df, column, ascending=True):\n",
        "        \"\"\"Heap Sort - O(n log n)\"\"\"\n",
        "        df_copy = df.copy().reset_index(drop=True)\n",
        "        n = len(df_copy)\n",
        "\n",
        "        def heapify(df_local, n_local, i_local):\n",
        "            largest_or_smallest = i_local\n",
        "            left = 2 * i_local + 1\n",
        "            right = 2 * i_local + 2\n",
        "\n",
        "            if ascending:\n",
        "                if left < n_local and df_local.loc[i_local, column] < df_local.loc[left, column]:\n",
        "                    largest_or_smallest = left\n",
        "                if right < n_local and df_local.loc[largest_or_smallest, column] < df_local.loc[right, column]:\n",
        "                    largest_or_smallest = right\n",
        "            else: # Descending\n",
        "                if left < n_local and df_local.loc[i_local, column] > df_local.loc[left, column]:\n",
        "                    largest_or_smallest = left\n",
        "                if right < n_local and df_local.loc[largest_or_smallest, column] > df_local.loc[right, column]:\n",
        "                    largest_or_smallest = right\n",
        "\n",
        "            if largest_or_smallest != i_local:\n",
        "                df_local.iloc[i_local], df_local.iloc[largest_or_smallest] = df_local.iloc[largest_or_smallest].copy(), df_local.iloc[i_local].copy()\n",
        "                heapify(df_local, n_local, largest_or_smallest)\n",
        "\n",
        "        for i in range(n // 2 - 1, -1, -1):\n",
        "            heapify(df_copy, n, i)\n",
        "\n",
        "        for i in range(n - 1, 0, -1):\n",
        "            df_copy.iloc[i], df_copy.iloc[0] = df_copy.iloc[0].copy(), df_copy.iloc[i].copy()\n",
        "            heapify(df_copy, i, 0)\n",
        "\n",
        "        return df_copy\n",
        "\n",
        "    @staticmethod\n",
        "    def shell_sort(df, column, ascending=True):\n",
        "        \"\"\"Shell Sort - Complejidad variable, mejor que O(n¬≤)\"\"\"\n",
        "        df_copy = df.copy().reset_index(drop=True)\n",
        "        n = len(df_copy)\n",
        "        gap = n // 2\n",
        "        while gap > 0:\n",
        "            for i in range(gap, n):\n",
        "                temp_row = df_copy.iloc[i].copy()\n",
        "                temp_val = temp_row[column]\n",
        "                j = i\n",
        "                if ascending:\n",
        "                    while j >= gap and df_copy.loc[j - gap, column] > temp_val:\n",
        "                        df_copy.iloc[j] = df_copy.iloc[j - gap].copy()\n",
        "                        j -= gap\n",
        "                else: # Descending\n",
        "                    while j >= gap and df_copy.loc[j - gap, column] < temp_val:\n",
        "                        df_copy.iloc[j] = df_copy.iloc[j - gap].copy()\n",
        "                        j -= gap\n",
        "                df_copy.iloc[j] = temp_row\n",
        "            gap //= 2\n",
        "        return df_copy\n",
        "\n",
        "    @staticmethod\n",
        "    def counting_sort(df, column, ascending=True):\n",
        "        \"\"\"Counting Sort - O(n + k) - Solo para enteros no negativos\"\"\"\n",
        "        if not pd.api.types.is_integer_dtype(df[column]) or (df[column] < 0).any():\n",
        "            raise ValueError(\"Counting Sort solo funciona con enteros no negativos.\")\n",
        "\n",
        "        df_copy = df.copy()\n",
        "        max_val = df_copy[column].max()\n",
        "        count = np.zeros(max_val + 1, dtype=int)\n",
        "\n",
        "        for val in df_copy[column]:\n",
        "            count[val] += 1\n",
        "\n",
        "        for i in range(1, len(count)):\n",
        "            count[i] += count[i-1]\n",
        "\n",
        "        output = [None] * len(df_copy)\n",
        "        for i in range(len(df_copy) - 1, -1, -1):\n",
        "            row = df_copy.iloc[i]\n",
        "            val = row[column]\n",
        "            output[count[val] - 1] = row\n",
        "            count[val] -= 1\n",
        "\n",
        "        result_df = pd.DataFrame(output)\n",
        "        if not ascending:\n",
        "            result_df = result_df.iloc[::-1]\n",
        "\n",
        "        return result_df.reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def radix_sort(df, column, ascending=True):\n",
        "        \"\"\"Radix Sort - O(d * (n + k)) - Solo para enteros no negativos\"\"\"\n",
        "        if not pd.api.types.is_integer_dtype(df[column]) or (df[column] < 0).any():\n",
        "             raise ValueError(\"Radix Sort solo funciona con enteros no negativos.\")\n",
        "\n",
        "        df_copy = df.copy()\n",
        "        max_val = df_copy[column].max()\n",
        "        exp = 1\n",
        "        while max_val // exp > 0:\n",
        "            df_copy = SortingAlgorithms._counting_sort_for_radix(df_copy, column, exp)\n",
        "            exp *= 10\n",
        "\n",
        "        if not ascending:\n",
        "            df_copy = df_copy.iloc[::-1]\n",
        "\n",
        "        return df_copy.reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def _counting_sort_for_radix(df, column, exp):\n",
        "        n = len(df)\n",
        "        output = [None] * n\n",
        "        count = [0] * 10\n",
        "\n",
        "        for i in range(n):\n",
        "            index = df.loc[i, column] // exp\n",
        "            count[index % 10] += 1\n",
        "\n",
        "        for i in range(1, 10):\n",
        "            count[i] += count[i - 1]\n",
        "\n",
        "        i = n - 1\n",
        "        while i >= 0:\n",
        "            index = df.loc[i, column] // exp\n",
        "            output[count[index % 10] - 1] = df.iloc[i].to_dict()\n",
        "            count[index % 10] -= 1\n",
        "            i -= 1\n",
        "\n",
        "        return pd.DataFrame(output)\n",
        "\n",
        "    @staticmethod\n",
        "    def tim_sort(df, column, ascending=True):\n",
        "        \"\"\"Tim Sort (implementaci√≥n de Pandas) - O(n log n)\"\"\"\n",
        "        # kind='mergesort' o 'stable' es similar a Timsort\n",
        "        return df.sort_values(by=column, ascending=ascending, kind='stable').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3L8nCCtnvYru"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FUNCI√ìN DE PARTICIONAMIENTO MEJORADA\n",
        "# ========================================\n",
        "\n",
        "def df_partition(df, criterion, percentage=0.25, partition_type=\"best\",\n",
        "                 sorting_algorithm=\"quick_sort\"):\n",
        "    \"\"\"\n",
        "    Segmenta un DataFrame seg√∫n un criterio usando un algoritmo de ordenamiento espec√≠fico.\n",
        "\n",
        "    Par√°metros:\n",
        "    - df: DataFrame de entrada\n",
        "    - criterion: Columna para ordenar\n",
        "    - percentage: Porcentaje del segmento (0.0 a 1.0)\n",
        "    - partition_type: \"best\" (valores m√°s altos) o \"worst\" (valores m√°s bajos)\n",
        "    - sorting_algorithm: Nombre del algoritmo a usar de la clase SortingAlgorithms\n",
        "    \"\"\"\n",
        "    if not 0 < percentage <= 1:\n",
        "        raise ValueError(\"El porcentaje debe estar entre 0 y 1\")\n",
        "\n",
        "    sorter = SortingAlgorithms()\n",
        "    sort_method = getattr(sorter, sorting_algorithm, None)\n",
        "\n",
        "    if sort_method is None:\n",
        "        raise ValueError(f\"Algoritmo '{sorting_algorithm}' no disponible en SortingAlgorithms\")\n",
        "\n",
        "    # Para \"best\" queremos orden descendente, para \"worst\" ascendente.\n",
        "    # Pero para tomar el primer segmento, siempre ordenamos y tomamos el inicio.\n",
        "    # La clave es el orden de clasificaci√≥n.\n",
        "    # Best (m√°s altos) -> descending=False -> ascending=False\n",
        "    # Worst (m√°s bajos) -> ascending=True\n",
        "    ascending_order = (partition_type == \"worst\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # El orden descendente se logra con ascending=False\n",
        "    df_sorted = sort_method(df, criterion, ascending=not ascending_order)\n",
        "\n",
        "    partition_size = int(len(df) * percentage)\n",
        "\n",
        "    # Tomamos el primer 'partition_size' de filas, que ser√°n las mejores o peores.\n",
        "    df_result = df_sorted.iloc[:partition_size].copy()\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    print(f\"Algoritmo usado: {sorting_algorithm}\")\n",
        "    print(f\"Tiempo de ejecuci√≥n: {execution_time:.6f} segundos\")\n",
        "    print(f\"Tama√±o de la partici√≥n '{partition_type}': {len(df_result)} filas\")\n",
        "\n",
        "    return df_result, execution_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "At6TFTuWvjXt"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 1: GENERACI√ìN DE DATOS\n",
        "# ========================================\n",
        "print(\"=\"*80)\n",
        "print(\"PASO 1: GENERANDO DATASET DE EJEMPLO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "n_rows = 10000\n",
        "\n",
        "# Generate heterogeneous data with specified relationships and correlations\n",
        "data = {}\n",
        "data['x1'] = np.random.rand(n_rows) * 100\n",
        "data['x2'] = np.random.rand(n_rows) * 100\n",
        "data['x5'] = np.random.rand(n_rows) * 100\n",
        "data['x7'] = np.random.rand(n_rows) * 100\n",
        "\n",
        "# Variables with specific relationships and noise\n",
        "x6 = np.random.rand(n_rows) * 0.1 + 0.9 * np.sin(np.arange(n_rows) / 500)\n",
        "x9 = np.random.rand(n_rows) * 0.1 + 0.9 * np.sin(np.arange(n_rows) / 500)\n",
        "x4 = np.random.randint(0, 100, n_rows)\n",
        "x8 = np.random.rand(n_rows) * 100\n",
        "\n",
        "# Introduce correlations for x3, x6, x9\n",
        "cov_matrix_x3_x6_x9 = [[1, 0.75, 0.75],\n",
        "                       [0.75, 1, 0.75],\n",
        "                       [0.75, 0.75, 1]]\n",
        "correlated_x3_x6_x9 = np.random.multivariate_normal([0, 0, 0], cov_matrix_x3_x6_x9, n_rows)\n",
        "data['x3'] = correlated_x3_x6_x9[:, 0] * np.std(x6) + np.mean(x6)\n",
        "data['x6'] = correlated_x3_x6_x9[:, 1] * np.std(x6) + np.mean(x6)\n",
        "data['x9'] = correlated_x3_x6_x9[:, 2] * np.std(x9) + np.mean(x9)\n",
        "\n",
        "# Introduce correlations for x10, x4, x6, x8\n",
        "cov_matrix_x10_x4_x6_x8 = [[1, 0.85, 0.85, 0.85],\n",
        "                           [0.85, 1, 0.85, 0.85],\n",
        "                           [0.85, 0.85, 1, 0.85],\n",
        "                           [0.85, 0.85, 0.85, 1]]\n",
        "correlated_x10_x4_x6_x8 = np.random.multivariate_normal([0, 0, 0, 0], cov_matrix_x10_x4_x6_x8, n_rows)\n",
        "data['x10'] = correlated_x10_x4_x6_x8[:, 0]\n",
        "data['x4'] = correlated_x10_x4_x6_x8[:, 1] * np.std(x4) + np.mean(x4)\n",
        "data['x6'] = correlated_x10_x4_x6_x8[:, 2] * np.std(x6) + np.mean(x6)\n",
        "data['x8'] = correlated_x10_x4_x6_x8[:, 3] * np.std(x8) + np.mean(x8)\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ==========================================\n",
        "# Crear la variable y = x3 * x10\n",
        "# Con distribuci√≥n gaussiana\n",
        "# ==========================================\n",
        "\n",
        "# Calcular el producto base\n",
        "y_base = df['x3'] * df['x10']\n",
        "\n",
        "# Normalizar a media 0 y desviaci√≥n est√°ndar 1\n",
        "y_normalized = (y_base - y_base.mean()) / y_base.std()\n",
        "\n",
        "# A√±adir ruido gaussiano para mejorar la distribuci√≥n normal\n",
        "ruido_gaussiano = np.random.normal(0, 0.1, n_rows)  # Media 0, std peque√±a\n",
        "y = y_normalized + ruido_gaussiano\n",
        "\n",
        "\n",
        "\n",
        "# A√±adir la variable a la dataframe\n",
        "df['y'] = y\n",
        "\n",
        "print(f\"\\nDataset creado con {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
        "print(\"\\nPrimeras 5 filas del dataset:\")\n",
        "display(df.head())\n",
        "print(\"\\nEstad√≠sticas de la columna 'y':\")\n",
        "print(df['y'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ted_4fa8zt9U"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 2: COMPARAR ALGORITMOS Y CREAR PARTICIONES\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 2.1: COMPARANDO RENDIMIENTO DE ALGORITMOS DE ORDENAMIENTO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Algoritmos eficientes a comparar\n",
        "algorithms_to_compare = ['quick_sort', 'merge_sort']\n",
        "for algo in algorithms_to_compare:\n",
        "    print(f\"\\n--- Probando: {algo.replace('_', ' ').title()} ---\")\n",
        "    df_partition(df, 'y', percentage=0.25, partition_type=\"best\", sorting_algorithm=algo)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"PASO 2.2: CREANDO PARTICIONES CON EL ALGORITMO ELEGIDO (quick_sort)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Seleccionamos quick_sort por su buen rendimiento general\n",
        "selected_algorithm = 'quick_sort'\n",
        "B4C, _ = df_partition(df, 'y', 0.25, \"best\", selected_algorithm)\n",
        "W4C, _ = df_partition(df, 'y', 0.25, \"worst\", selected_algorithm)\n",
        "\n",
        "print(\"\\nPartici√≥n de los MEJORES 25% (B4C):\")\n",
        "display(B4C.head())\n",
        "print(\"\\nPartici√≥n de los PEORES 25% (W4C):\")\n",
        "display(W4C.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_fwjrxD9wiKe"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 3: CREACI√ìN Y AN√ÅLISIS DETALLADO DE PARTICIONES\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3.1: CREANDO M√öLTIPLES PARTICIONES CON 'quick_sort'\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "selected_algorithm = 'quick_sort'\n",
        "\n",
        "# Crear particiones\n",
        "B2C, _ = df_partition(df, 'y', 0.50, \"best\", selected_algorithm)\n",
        "W2C, _ = df_partition(df, 'y', 0.50, \"worst\", selected_algorithm)\n",
        "B4C, _ = df_partition(df, 'y', 0.25, \"best\", selected_algorithm)\n",
        "W4C, _ = df_partition(df, 'y', 0.25, \"worst\", selected_algorithm)\n",
        "B8C, _ = df_partition(df, 'y', 0.125, \"best\", selected_algorithm)\n",
        "W8C, _ = df_partition(df, 'y', 0.125, \"worst\", selected_algorithm)\n",
        "B16C, _ = df_partition(df, 'y', 0.0625, \"best\", selected_algorithm)\n",
        "W16C, _ = df_partition(df, 'y', 0.0625, \"worst\", selected_algorithm)\n",
        "\n",
        "print(\"\\nResumen de tama√±os de las particiones:\")\n",
        "print(f\"B2C (Best 50%): {B2C.shape}\")\n",
        "print(f\"W2C (Worst 50%): {W2C.shape}\")\n",
        "print(f\"B4C (Best 25%): {B4C.shape}\")\n",
        "print(f\"W4C (Worst 25%): {W4C.shape}\")\n",
        "print(f\"B8C (Best 12.5%): {B8C.shape}\")\n",
        "print(f\"W8C (Worst 12.5%): {W8C.shape}\")\n",
        "print(f\"B16C (Best 6.25%): {B16C.shape}\")\n",
        "print(f\"W16C (Worst 6.25%): {W16C.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xkKRN4Mb2XD0"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 3.2: AN√ÅLISIS ESTAD√çSTICO DE LAS PARTICIONES\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3.2: AN√ÅLISIS ESTAD√çSTICO DE LAS PARTICIONES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "particiones = {\n",
        "    'df_original': df, 'B2C': B2C, 'W2C': W2C, 'B4C': B4C, 'W4C': W4C,\n",
        "    'B8C': B8C, 'W8C': W8C, 'B16C': B16C, 'W16C': W16C\n",
        "}\n",
        "\n",
        "estadisticas = []\n",
        "for nombre, partition_df in particiones.items():\n",
        "    stats = {\n",
        "        'Partici√≥n': nombre,\n",
        "        'Tama√±o': len(partition_df),\n",
        "        'Min_y': partition_df['y'].min(),\n",
        "        'Max_y': partition_df['y'].max(),\n",
        "        'Media_y': partition_df['y'].mean(),\n",
        "        'Mediana_y': partition_df['y'].median(),\n",
        "        'Std_Dev_y': partition_df['y'].std()\n",
        "    }\n",
        "    estadisticas.append(stats)\n",
        "\n",
        "df_stats = pd.DataFrame(estadisticas).set_index('Partici√≥n')\n",
        "display(df_stats.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4a0ne9Qw2cCH"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 3.3: VISUALIZACI√ìN DE DENSIDAD\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3.3: GR√ÅFICO DE DENSIDAD DE 'y' POR PARTICI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "plt.figure(figsize=(18, 8))\n",
        "# Graficar solo las particiones para no saturar el gr√°fico\n",
        "sns.kdeplot(data=df['y'], label='Original', fill=True, alpha=0.2, color='grey')\n",
        "sns.kdeplot(data=B4C['y'], label='B4C (Mejores 25%)', fill=True, alpha=0.5)\n",
        "sns.kdeplot(data=W4C['y'], label='W4C (Peores 25%)', fill=True, alpha=0.5)\n",
        "sns.kdeplot(data=B16C['y'], label='B16C (Mejores 6.25%)', fill=True, alpha=0.5)\n",
        "sns.kdeplot(data=W16C['y'], label='W16C (Peores 6.25%)', fill=True, alpha=0.5)\n",
        "sns.kdeplot(data=B2C['y'], label='B2C (Mejores 50%)', fill=True, alpha=0.8)\n",
        "sns.kdeplot(data=W2C['y'], label='W2C (Peores 50%)', fill=True, alpha=0.8)\n",
        "sns.kdeplot(data=B8C['y'], label='B8C (Mejores 12.50%)', fill=True, alpha=0.3)\n",
        "sns.kdeplot(data=W8C['y'], label='W8C (Peores 12.50%)', fill=True, alpha=0.3)\n",
        "\n",
        "\n",
        "plt.title('Distribuci√≥n de la Variable \"y\" en Diferentes Particiones', fontsize=16)\n",
        "plt.xlabel('Valor de y', fontsize=12)\n",
        "plt.ylabel('Densidad', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zmiZcPGz2jf_"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO 3.4: VISUALIZACI√ìN DE DIAGRAMA DE CAJAS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3.4: DIAGRAMA DE CAJAS DE 'y' POR PARTICI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Preparar datos y etiquetas para el boxplot\n",
        "data_to_plot = [B2C['y'], W2C['y'], B4C['y'], W4C['y'], B8C['y'], W8C['y'], B16C['y'], W16C['y']]\n",
        "labels = ['B2C', 'W2C', 'B4C', 'W4C', 'B8C', 'W8C', 'B16C', 'W16C']\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.boxplot(data_to_plot, labels=labels, vert=False, patch_artist=True)\n",
        "plt.title('Distribuci√≥n de \"y\" por Partici√≥n', fontsize=16)\n",
        "plt.xlabel('Valor de y', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xI7rwD0QHNqs"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# CORRELACI√ìN DE PEARSON CON THRESHOLD FIJO\n",
        "# Usuario define el threshold\n",
        "# MUESTRA MATRIZ COMPLETA Y LA GRAFICA EN UN MAPA DE CALOR\n",
        "# ========================================\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # <--- MODIFICACI√ìN: Importar matplotlib\n",
        "import seaborn as sns         # <--- MODIFICACI√ìN: Importar seaborn\n",
        "\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"AN√ÅLISIS DE CORRELACI√ìN DE PEARSON CON THRESHOLD FIJO (Y MATRIZ GR√ÅFICA)\")\n",
        "print(\"=\"*120)\n",
        "\n",
        "# ‚≠ê PAR√ÅMETRO CONFIGURABLE POR EL USUARIO ‚≠ê\n",
        "THRESHOLD = 0.01  # ‚Üê CAMBIA ESTE VALOR AQU√ç\n",
        "\n",
        "print(f\"\\nüìä CONFIGURACI√ìN:\")\n",
        "print(f\"   Threshold: {THRESHOLD}\")\n",
        "print(f\"   Solo correlaciones POSITIVAS r ‚â• {THRESHOLD}\\n\")\n",
        "\n",
        "# Diccionario para almacenar resultados\n",
        "resultados_pearson = {}\n",
        "\n",
        "# --- Asumiendo que estos DataFrames existen en tu entorno ---\n",
        "# (Creando dummies para que el script sea ejecutable)\n",
        "try:\n",
        "    df, B2C, W2C, B4C, W4C, B8C, W8C, B16C, W16C\n",
        "except NameError:\n",
        "    print(\"ADVERTENCIA: Creando DataFrames de ejemplo...\")\n",
        "    data_ejemplo = {\n",
        "        'VarA': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "        'VarB': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], # Correlaci√≥n Fuerte con A\n",
        "        'VarC': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1], # Correlaci√≥n Fuerte Negativa con A\n",
        "        'VarD': [1, 3, 2, 5, 4, 7, 6, 9, 8, 10], # Correlaci√≥n Moderada\n",
        "        'VarE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # Cero varianza\n",
        "        'VarF': [5, 6, 5, 6, 5, 6, 5, 6, 5, 6]  # Baja varianza\n",
        "    }\n",
        "    df = pd.DataFrame(data_ejemplo)\n",
        "    B2C = df.head(5)\n",
        "    W2C = df.tail(5)\n",
        "    B4C = df.head(3)\n",
        "    W4C = df.tail(3)\n",
        "    B8C = df.head(8)\n",
        "    W8C = df.tail(8)\n",
        "    B16C = df.head(6)\n",
        "    W16C = df.tail(6)\n",
        "    print(\"...DataFrames de ejemplo creados.\\n\")\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Particiones a analizar\n",
        "particiones_analizar = {\n",
        "    'df_original': df,\n",
        "    'B2C': B2C,\n",
        "    'W2C': W2C,\n",
        "    'B4C': B4C,\n",
        "    'W4C': W4C,\n",
        "    'B8C': B8C,\n",
        "    'W8C': W8C,\n",
        "    'B16C': B16C,\n",
        "    'W16C': W16C\n",
        "}\n",
        "\n",
        "# <--- INICIO MODIFICACI√ìN: Funci√≥n para generar el mapa de calor ---\n",
        "def plot_correlation_heatmap(correlation_df, partition_name, threshold=None):\n",
        "    if correlation_df.empty:\n",
        "        print(f\"  No se puede generar mapa de calor para {partition_name}: DataFrame de correlaci√≥n vac√≠o.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(len(correlation_df.columns)*0.8, len(correlation_df.index)*0.8)) # Tama√±o din√°mico\n",
        "\n",
        "    title = f'Mapa de Calor de Correlaci√≥n de Pearson - {partition_name}'\n",
        "    if threshold is not None:\n",
        "        title += f' (Threshold r ‚â• {threshold})'\n",
        "\n",
        "    sns.heatmap(\n",
        "        correlation_df,\n",
        "        annot=True,          # Mostrar los valores de correlaci√≥n en el mapa\n",
        "        cmap='coolwarm',     # Esquema de color (rojo para negativo, azul para positivo)\n",
        "        fmt=\".2f\",           # Formato de los n√∫meros a dos decimales\n",
        "        linewidths=.5,       # L√≠neas entre las celdas\n",
        "        vmin=-1, vmax=1      # Asegurar que la escala de color va de -1 a 1\n",
        "    )\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout() # Ajusta el dise√±o para que todo quepa\n",
        "\n",
        "    filename = f'pearson_heatmap_{partition_name}.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close() # Cierra la figura para liberar memoria\n",
        "    print(f\"  ‚úÖ Mapa de calor guardado: {filename}\")\n",
        "# <--- FIN MODIFICACI√ìN ---\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# LOOP PRINCIPAL - ANALIZAR CADA PARTICI√ìN\n",
        "# ========================================\n",
        "\n",
        "for nombre_particion, partition_df in particiones_analizar.items():\n",
        "\n",
        "    n_datos = len(partition_df)\n",
        "\n",
        "    print(f\"\\n{'='*120}\")\n",
        "    print(f\"PARTICI√ìN: {nombre_particion.upper()} ({n_datos} filas)\")\n",
        "    print(f\"{'='*120}\\n\")\n",
        "\n",
        "    # 1. Obtener columnas num√©ricas\n",
        "    numerical_cols = []\n",
        "    if n_datos == 0:\n",
        "        print(\"1. DataFrame vac√≠o (0 filas).\")\n",
        "        resultados_pearson[nombre_particion] = {'n_datos': 0, 'threshold': THRESHOLD, 'aristas': [], 'num_aristas': 0, 'matriz_completa': pd.DataFrame()}\n",
        "        continue # Saltar al siguiente partici√≥n\n",
        "\n",
        "    for col in partition_df.columns:\n",
        "        try:\n",
        "            # Intentar convertir el primer valor (ignorar si est√° vac√≠o)\n",
        "            # Tambi√©n considerar el caso donde toda la columna es NaN o no-num√©rica despu√©s de filtrado\n",
        "            if pd.to_numeric(partition_df[col], errors='coerce').notna().any(): # Verifica si hay alg√∫n valor num√©rico v√°lido\n",
        "                numerical_cols.append(col)\n",
        "        except (ValueError, TypeError, IndexError):\n",
        "            pass\n",
        "\n",
        "    if not numerical_cols:\n",
        "        print(\"1. No se encontraron columnas num√©ricas o el DataFrame es demasiado peque√±o.\")\n",
        "        resultados_pearson[nombre_particion] = {'n_datos': n_datos, 'threshold': THRESHOLD, 'aristas': [], 'num_aristas': 0, 'matriz_completa': pd.DataFrame()}\n",
        "        continue\n",
        "\n",
        "    print(f\"1. Variables num√©ricas: {numerical_cols}\")\n",
        "\n",
        "    # Crear la matriz de correlaci√≥n (DataFrame vac√≠o)\n",
        "    corr_matrix_df = pd.DataFrame(index=numerical_cols, columns=numerical_cols, dtype=float)\n",
        "\n",
        "    # 2. Calcular correlaciones de Pearson\n",
        "    print(f\"\\n2. Calculando correlaciones de Pearson...\\n\")\n",
        "\n",
        "    aristas_significativas = []\n",
        "\n",
        "    # Rellenar la matriz de correlaci√≥n completa\n",
        "    for i in range(len(numerical_cols)):\n",
        "        col1_name = numerical_cols[i]\n",
        "        corr_matrix_df.loc[col1_name, col1_name] = 1.0\n",
        "\n",
        "        for j in range(i + 1, len(numerical_cols)):\n",
        "            col2_name = numerical_cols[j]\n",
        "\n",
        "            # Obtener valores (filtrando NaNs si los hay)\n",
        "            # Usamos pd.to_numeric para manejar no-num√©ricos y luego dropear NaNs\n",
        "            series1 = pd.to_numeric(partition_df[col1_name], errors='coerce').dropna()\n",
        "            series2 = pd.to_numeric(partition_df[col2_name], errors='coerce').dropna()\n",
        "\n",
        "            # Asegurarse de que ambas series tienen los mismos √≠ndices para un c√°lculo correcto\n",
        "            # Si se espera que los DataFrames no tengan NaNs en las columnas num√©ricas, esto es redundante\n",
        "            # Pero es una buena pr√°ctica para robustez\n",
        "            common_index = series1.index.intersection(series2.index)\n",
        "\n",
        "            col1_vals = series1.loc[common_index].tolist()\n",
        "            col2_vals = series2.loc[common_index].tolist()\n",
        "\n",
        "            n_valid_datos = len(col1_vals) # N√∫mero de datos v√°lidos para este par\n",
        "\n",
        "            r = 0.0 # Valor por defecto si no hay suficientes datos\n",
        "            if n_valid_datos > 1: # Se necesitan al menos 2 puntos para calcular correlaci√≥n\n",
        "                media_x = sum(col1_vals) / n_valid_datos\n",
        "                media_y = sum(col2_vals) / n_valid_datos\n",
        "\n",
        "                suma_xy = sum((col1_vals[k] - media_x) * (col2_vals[k] - media_y) for k in range(n_valid_datos))\n",
        "                suma_x2 = sum((col1_vals[k] - media_x) ** 2 for k in range(n_valid_datos))\n",
        "                suma_y2 = sum((col2_vals[k] - media_y) ** 2 for k in range(n_valid_datos))\n",
        "\n",
        "                denom = math.sqrt(suma_x2 * suma_y2)\n",
        "                if denom != 0:\n",
        "                    r = suma_xy / denom\n",
        "                # else r = 0.0 (ya inicializado)\n",
        "            # else r = 0.0 (ya inicializado)\n",
        "\n",
        "            # Guardar en la matriz (antes de filtrar)\n",
        "            corr_matrix_df.loc[col1_name, col2_name] = r\n",
        "            corr_matrix_df.loc[col2_name, col1_name] = r\n",
        "\n",
        "            # FILTRAR: Solo positivas Y mayor o igual al threshold\n",
        "            if r >= THRESHOLD:\n",
        "                aristas_significativas.append({\n",
        "                    'var1': col1_name,\n",
        "                    'var2': col2_name,\n",
        "                    'r_pearson': r\n",
        "                })\n",
        "\n",
        "    # 2b. MOSTRAR LA MATRIZ COMPLETA (en texto)\n",
        "    if not corr_matrix_df.empty:\n",
        "        print(f\"2b. Matriz de Correlaci√≥n de Pearson COMPLETA:\\n\")\n",
        "        print(corr_matrix_df.to_string(float_format=\"%.6f\"))\n",
        "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "        # <--- INICIO MODIFICACI√ìN: Generar y mostrar el mapa de calor ---\n",
        "        print(\"  Generando mapa de calor...\")\n",
        "        plot_correlation_heatmap(corr_matrix_df, nombre_particion)\n",
        "        # --- FIN MODIFICACI√ìN ---\n",
        "\n",
        "    else:\n",
        "        print(\"2b. No se pudo generar una matriz de correlaci√≥n (no hay columnas num√©ricas v√°lidas).\")\n",
        "\n",
        "    # Ordenar por correlaci√≥n descendente\n",
        "    aristas_significativas.sort(key=lambda x: x['r_pearson'], reverse=True)\n",
        "\n",
        "    num_aristas = len(aristas_significativas)\n",
        "    print(f\"3. Aristas encontradas (r ‚â• {THRESHOLD}): {num_aristas}\\n\")\n",
        "\n",
        "    # Estad√≠sticas\n",
        "    if len(aristas_significativas) > 0:\n",
        "        r_max = max([a['r_pearson'] for a in aristas_significativas])\n",
        "        r_min = min([a['r_pearson'] for a in aristas_significativas])\n",
        "        r_prom = sum([a['r_pearson'] for a in aristas_significativas]) / len(aristas_significativas)\n",
        "\n",
        "        print(f\"4. Estad√≠sticas (filtradas):\")\n",
        "        print(f\"   Correlaci√≥n m√°xima: {r_max:.6f}\")\n",
        "        print(f\"   Correlaci√≥n m√≠nima: {r_min:.6f}\")\n",
        "        print(f\"   Correlaci√≥n promedio: {r_prom:.6f}\\n\")\n",
        "\n",
        "        # Mostrar todas o top 15\n",
        "        num_mostrar = min(15, len(aristas_significativas))\n",
        "        print(f\"5. Top {num_mostrar} correlaciones (filtradas):\\n\")\n",
        "        print(f\"   {'N¬∫':<4} {'Variable 1':<12} {'Variable 2':<12} {'Pearson r':<15}\")\n",
        "        print(f\"   {'-'*50}\")\n",
        "\n",
        "        for idx, arista in enumerate(aristas_significativas[:num_mostrar], 1):\n",
        "            print(f\"   {idx:<4} {arista['var1']:<12} {arista['var2']:<12} {arista['r_pearson']:>+.8f}\")\n",
        "\n",
        "        if len(aristas_significativas) > 15:\n",
        "            print(f\"\\n   ... y {len(aristas_significativas) - 15} m√°s\")\n",
        "    else:\n",
        "        print(f\" 4. ‚ö†Ô∏è   Sin correlaciones positivas por encima del threshold ({THRESHOLD})\\n\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    resultados_pearson[nombre_particion] = {\n",
        "        'n_datos': n_datos,\n",
        "        'threshold': THRESHOLD,\n",
        "        'aristas': aristas_significativas,\n",
        "        'num_aristas': num_aristas,\n",
        "        'matriz_completa': corr_matrix_df\n",
        "    }\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# TABLA COMPARATIVA GENERAL\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n\\n{'='*120}\")\n",
        "print(\"TABLA COMPARATIVA: RESULTADOS POR PARTICI√ìN\")\n",
        "print(f\"{'='*120}\\n\")\n",
        "\n",
        "print(f\"Threshold aplicado: {THRESHOLD}\\n\")\n",
        "\n",
        "print(f\"{'Partici√≥n':<15} {'Filas':<10} {'Aristas':<12} {'r_M√°x':<15} {'r_M√≠n':<15} {'r_Prom':<15} {'Ratio':<12}\")\n",
        "print(\"-\"*120)\n",
        "\n",
        "for nombre, datos in resultados_pearson.items():\n",
        "    n = datos['n_datos']\n",
        "    num_aristas = datos['num_aristas']\n",
        "\n",
        "    if len(datos['aristas']) > 0:\n",
        "        r_max = max([a['r_pearson'] for a in datos['aristas']])\n",
        "        r_min = min([a['r_pearson'] for a in datos['aristas']])\n",
        "        r_prom = sum([a['r_pearson'] for a in datos['aristas']]) / len(datos['aristas'])\n",
        "        ratio = num_aristas / n if n > 0 else 0\n",
        "    else:\n",
        "        r_max = 0\n",
        "        r_min = 0\n",
        "        r_prom = 0\n",
        "        ratio = 0\n",
        "\n",
        "    print(f\"{nombre:<15} {n:<10} {num_aristas:<12} {r_max:>+.8f}    \"\n",
        "          f\"{r_min:>+.8f}    {r_prom:>+.8f}    {ratio:.6f}\")\n",
        "\n",
        "print(\"=\"*120)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# GR√ÅFICO COMPARATIVO ASCII\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n\\n{'='*120}\")\n",
        "print(\"VISUALIZACI√ìN: N√öMERO DE ARISTAS POR PARTICI√ìN\")\n",
        "print(f\"{'='*120}\\n\")\n",
        "\n",
        "max_aristas = max([datos['num_aristas'] for datos in resultados_pearson.values()] + [0]) # +[0] para evitar error si todo est√° vac√≠o\n",
        "\n",
        "for nombre, datos in resultados_pearson.items():\n",
        "    num_aristas = datos['num_aristas']\n",
        "\n",
        "    if max_aristas > 0:\n",
        "        barra_len = int((num_aristas / max_aristas) * 50)\n",
        "    else:\n",
        "        barra_len = 0\n",
        "\n",
        "    barra = \"‚ñà\" * barra_len + \"‚ñë\" * (50 - barra_len)\n",
        "\n",
        "    print(f\"{nombre:<15} ‚îÇ{barra}‚îÇ {num_aristas:>3} aristas\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# AN√ÅLISIS POR RANGO DE CORRELACI√ìN\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*120}\")\n",
        "print(\"DISTRIBUCI√ìN POR RANGOS DE CORRELACI√ìN (Sobre aristas filtradas)\")\n",
        "print(f\"{'='*120}\\n\")\n",
        "\n",
        "rangos = {\n",
        "    f'Muy fuerte (r ‚â• 0.9)': (0.9, 1.0),\n",
        "    f'Fuerte (0.8 ‚â§ r < 0.9)': (0.8, 0.9),\n",
        "    f'Moderada (0.7 ‚â§ r < 0.8)': (0.7, 0.8),\n",
        "    f'D√©bil ({THRESHOLD} ‚â§ r < 0.7)': (THRESHOLD, 0.7),\n",
        "}\n",
        "\n",
        "for nombre, datos in resultados_pearson.items():\n",
        "    print(f\"\\n{nombre.upper()}:\")\n",
        "\n",
        "    if len(datos['aristas']) > 0:\n",
        "        total_aristas = len(datos['aristas'])\n",
        "        # Ajuste para incluir r = 1.0 en el rango \"Muy fuerte\"\n",
        "        rangos[f'Muy fuerte (r ‚â• 0.9)'] = (0.9, 1.01)\n",
        "\n",
        "        for rango_nombre, (min_r, max_r) in rangos.items():\n",
        "            count = sum(1 for a in datos['aristas'] if min_r <= a['r_pearson'] < max_r or (rango_nombre.startswith('Muy') and a['r_pearson'] == 1.0))\n",
        "            porcent = (count / total_aristas * 100) if total_aristas > 0 else 0\n",
        "\n",
        "            # Escalar barra para que no sea tan larga\n",
        "            barra_len_rango = int(porcent / 5) # 1 '‚ñà' por cada 5%\n",
        "            barra = \"‚ñà\" * barra_len_rango\n",
        "\n",
        "            print(f\"   {rango_nombre:<35} {barra:<20} {count:>3} ({porcent:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"   Sin aristas\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# EXPORTAR RESULTADOS\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*120}\")\n",
        "print(\"GUARDANDO RESULTADOS\")\n",
        "print(f\"{'='*120}\\n\")\n",
        "\n",
        "# Guardar tabla resumida\n",
        "with open('pearson_resumen.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write(f\"threshold,{THRESHOLD}\\n\")\n",
        "    f.write(\"Partici√≥n,Filas,Aristas,r_Max,r_Min,r_Promedio\\n\")\n",
        "\n",
        "    for nombre, datos in resultados_pearson.items():\n",
        "        n = datos['n_datos']\n",
        "        num_aristas = datos['num_aristas']\n",
        "\n",
        "        if len(datos['aristas']) > 0:\n",
        "            r_max = max([a['r_pearson'] for a in datos['aristas']])\n",
        "            r_min = min([a['r_pearson'] for a in datos['aristas']])\n",
        "            r_prom = sum([a['r_pearson'] for a in datos['aristas']]) / len(datos['aristas'])\n",
        "        else:\n",
        "            r_max = 0\n",
        "            r_min = 0\n",
        "            r_prom = 0\n",
        "\n",
        "        f.write(f\"{nombre},{n},{num_aristas},{r_max:.8f},{r_min:.8f},{r_prom:.8f}\\n\")\n",
        "\n",
        "print(\"‚úÖ Resumen guardado: pearson_resumen.csv\")\n",
        "\n",
        "# Guardar detalles de aristas por partici√≥n\n",
        "for nombre, datos in resultados_pearson.items():\n",
        "    filename_aristas = f\"pearson_aristas_{nombre}.csv\"\n",
        "    with open(filename_aristas, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"var1,var2,pearson_r\\n\")\n",
        "        for arista in datos['aristas']:\n",
        "            f.write(f\"{arista['var1']},{arista['var2']},{arista['r_pearson']:.8f}\\n\")\n",
        "\n",
        "    if len(datos['aristas']) > 0:\n",
        "        print(f\"‚úÖ Aristas guardadas: {filename_aristas} ({len(datos['aristas'])} correlaciones)\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è   Sin aristas para: {nombre} (archivo vac√≠o creado)\")\n",
        "\n",
        "    # Guardar la matriz de correlaci√≥n completa\n",
        "    filename_matriz = f\"pearson_matriz_completa_{nombre}.csv\"\n",
        "    if not datos['matriz_completa'].empty:\n",
        "        datos['matriz_completa'].to_csv(filename_matriz, encoding='utf-8', float_format='%.8f')\n",
        "        print(f\"‚úÖ Matriz completa guardada: {filename_matriz}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è   No hay matriz completa para guardar para: {nombre}\")\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*120}\")\n",
        "print(\"AN√ÅLISIS COMPLETADO\")\n",
        "print(f\"{'='*120}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g5VlooRLErbt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========================================\n",
        "# ALGORITMOS DE GRAFOS\n",
        "# ========================================\n",
        "\n",
        "class GraphAlgorithms:\n",
        "    \"\"\"Contiene implementaciones para MST (Kruskal y Prim).\"\"\"\n",
        "\n",
        "    class DSU:\n",
        "        \"\"\"Helper class for Disjoint Set Union (DSU), used by Kruskal.\"\"\"\n",
        "        def __init__(self, nodes):\n",
        "            self.parent = {node: node for node in nodes}\n",
        "\n",
        "        def find(self, i):\n",
        "            if self.parent[i] == i:\n",
        "                return i\n",
        "            self.parent[i] = self.find(self.parent[i])\n",
        "            return self.parent[i]\n",
        "\n",
        "        def union(self, x, y):\n",
        "            root_x = self.find(x)\n",
        "            root_y = self.find(y)\n",
        "            if root_x != root_y:\n",
        "                self.parent[root_x] = root_y\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def kruskal_mst(graph):\n",
        "        \"\"\"Calcula el MST usando Kruskal.\"\"\"\n",
        "        mst = nx.Graph()\n",
        "        mst.add_nodes_from(graph.nodes())\n",
        "        total_weight = 0\n",
        "\n",
        "        edges = sorted(graph.edges(data=True), key=lambda t: t[2].get('weight', 1))\n",
        "\n",
        "        dsu = GraphAlgorithms.DSU(graph.nodes())\n",
        "\n",
        "        for u, v, data in edges:\n",
        "            if dsu.union(u, v):\n",
        "                mst.add_edge(u, v, **data)\n",
        "                total_weight += data.get('weight', 1)\n",
        "\n",
        "        return mst, total_weight\n",
        "\n",
        "    @staticmethod\n",
        "    def prim_mst(graph, start_node=None):\n",
        "        \"\"\"Calcula el MST usando Prim.\"\"\"\n",
        "        mst = nx.Graph()\n",
        "        total_weight = 0\n",
        "\n",
        "        if not graph.nodes():\n",
        "            return mst, total_weight\n",
        "\n",
        "        if start_node is None or start_node not in graph:\n",
        "            valid_start_node = None\n",
        "            for node in graph.nodes():\n",
        "                if graph.degree(node) > 0:\n",
        "                    valid_start_node = node\n",
        "                    break\n",
        "            if valid_start_node is None:\n",
        "                if not graph.nodes():\n",
        "                    return mst, total_weight\n",
        "                valid_start_node = list(graph.nodes())[0]\n",
        "            start_node = valid_start_node\n",
        "\n",
        "        if start_node not in graph:\n",
        "             return mst, total_weight\n",
        "\n",
        "        mst.add_node(start_node)\n",
        "        priority_queue = []\n",
        "\n",
        "        for neighbor in graph.neighbors(start_node):\n",
        "            weight = graph[start_node][neighbor].get('weight', 1)\n",
        "            heapq.heappush(priority_queue, (weight, start_node, neighbor))\n",
        "\n",
        "        while priority_queue and mst.number_of_nodes() < graph.number_of_nodes():\n",
        "            weight, u, v = heapq.heappop(priority_queue)\n",
        "\n",
        "            if v not in mst.nodes():\n",
        "                mst.add_node(v)\n",
        "\n",
        "                edge_data = graph[u][v].copy()\n",
        "                edge_data.pop('weight', None)\n",
        "\n",
        "                mst.add_edge(u, v, weight=weight, **edge_data)\n",
        "                total_weight += weight\n",
        "\n",
        "                for neighbor in graph.neighbors(v):\n",
        "                    if neighbor not in mst.nodes():\n",
        "                        neighbor_weight = graph[v][neighbor].get('weight', 1)\n",
        "                        heapq.heappush(priority_queue, (neighbor_weight, v, neighbor))\n",
        "\n",
        "        for node in graph.nodes():\n",
        "            if node not in mst.nodes():\n",
        "                mst.add_node(node)\n",
        "\n",
        "        return mst, total_weight\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# FUNCI√ìN DE VISUALIZACI√ìN CORREGIDA\n",
        "# ========================================\n",
        "\n",
        "def visualize_graphs_and_mst(aristas_filtradas, numerical_cols, partition_name, threshold):\n",
        "    \"\"\"\n",
        "    Visualiza Grafo Original, MST Kruskal y MST Prim en configuraci√≥n 1x3.\n",
        "    VERSI√ìN CORREGIDA: Sin zorder en draw_networkx_nodes()\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generando Grafos y MSTs para: {partition_name} ---\")\n",
        "\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(numerical_cols)\n",
        "\n",
        "    if not aristas_filtradas:\n",
        "        print(f\"  ‚ö†Ô∏è  Sin aristas significativas (r >= {threshold}). El grafo no tendr√° aristas.\")\n",
        "    else:\n",
        "        for arista in aristas_filtradas:\n",
        "            r = arista['r_pearson']\n",
        "            weight = 1.0 - r\n",
        "            G.add_edge(arista['var1'], arista['var2'], weight=weight, correlation=r)\n",
        "\n",
        "    # Calcular MSTs\n",
        "    mst_kruskal, peso_k = GraphAlgorithms.kruskal_mst(G)\n",
        "    mst_prim, peso_p = GraphAlgorithms.prim_mst(G)\n",
        "\n",
        "    print(f\"  ‚úì Grafo Original: {G.number_of_nodes()} nodos, {G.number_of_edges()} aristas\")\n",
        "    print(f\"  ‚úì MST Kruskal: {mst_kruskal.number_of_nodes()} nodos, {mst_kruskal.number_of_edges()} aristas, Peso: {peso_k:.4f}\")\n",
        "    print(f\"  ‚úì MST Prim: {mst_prim.number_of_nodes()} nodos, {mst_prim.number_of_edges()} aristas, Peso: {peso_p:.4f}\")\n",
        "\n",
        "    # Crear figura 1x3\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(22, 8))\n",
        "    fig.suptitle(f\"An√°lisis de Grafo: {partition_name} (r >= {threshold})\", fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Calcular layout\n",
        "    k_layout = 1.5 / math.sqrt(max(1, G.number_of_nodes()))\n",
        "    pos = nx.spring_layout(G, seed=42, k=k_layout, iterations=50)\n",
        "\n",
        "    # Constantes de estilo\n",
        "    node_size = 2000\n",
        "    node_alpha = 0.85\n",
        "    font_size = 10\n",
        "\n",
        "    # ==========================================\n",
        "    # 1. GRAFO ORIGINAL\n",
        "    # ==========================================\n",
        "    ax1 = axes[0]\n",
        "\n",
        "    # Dibujar aristas con grosor din√°mico\n",
        "    if G.number_of_edges() > 0:\n",
        "        edge_correlations = [d['correlation'] for u, v, d in G.edges(data=True)]\n",
        "        max_width = 4.0\n",
        "        min_width = 0.5\n",
        "        range_denominator = (1.0 - threshold) if (1.0 - threshold) > 0 else 1.0\n",
        "        edge_widths = [\n",
        "            min_width + (corr - threshold) * (max_width - min_width) / range_denominator\n",
        "            for corr in edge_correlations\n",
        "        ]\n",
        "\n",
        "        nx.draw_networkx_edges(\n",
        "            G, pos, ax=ax1,\n",
        "            edgelist=G.edges(),\n",
        "            width=edge_widths,\n",
        "            edge_color=edge_correlations,\n",
        "            edge_cmap=plt.cm.Greens,\n",
        "            edge_vmin=threshold, edge_vmax=1.0,\n",
        "            alpha=0.7\n",
        "        )\n",
        "\n",
        "        # Etiquetas de aristas\n",
        "        edge_labels = {\n",
        "            (u, v): f\"{d['correlation']:.2f}\"\n",
        "            for u, v, d in G.edges(data=True)\n",
        "        }\n",
        "        nx.draw_networkx_edge_labels(\n",
        "            G, pos, ax=ax1,\n",
        "            edge_labels=edge_labels,\n",
        "            font_size=font_size - 2,\n",
        "            font_color='black'\n",
        "        )\n",
        "\n",
        "    # Dibujar nodos (SIN zorder)\n",
        "    nx.draw_networkx_nodes(\n",
        "        G, pos, ax=ax1, node_color='skyblue',\n",
        "        node_size=node_size, alpha=node_alpha,\n",
        "        edgecolors='black', linewidths=2\n",
        "    )\n",
        "\n",
        "    # Etiquetas de nodos\n",
        "    nx.draw_networkx_labels(\n",
        "        G, pos, ax=ax1,\n",
        "        font_size=font_size, font_weight='bold'\n",
        "    )\n",
        "\n",
        "    ax1.set_title(f\"Grafo de Correlaci√≥n Original\\n({G.number_of_edges()} aristas)\",\n",
        "                  fontsize=12, fontweight='bold', pad=10)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. MST KRUSKAL\n",
        "    # ==========================================\n",
        "    ax2 = axes[1]\n",
        "\n",
        "    # Dibujar aristas\n",
        "    nx.draw_networkx_edges(\n",
        "        mst_kruskal, pos, ax=ax2,\n",
        "        width=3, alpha=0.8, edge_color='darkgreen'\n",
        "    )\n",
        "\n",
        "    # Dibujar nodos (SIN zorder)\n",
        "    nx.draw_networkx_nodes(\n",
        "        mst_kruskal, pos, ax=ax2, node_color='lightgreen',\n",
        "        node_size=node_size, alpha=node_alpha,\n",
        "        edgecolors='darkgreen', linewidths=2\n",
        "    )\n",
        "\n",
        "    # Etiquetas\n",
        "    nx.draw_networkx_labels(\n",
        "        mst_kruskal, pos, ax=ax2,\n",
        "        font_size=font_size, font_weight='bold'\n",
        "    )\n",
        "\n",
        "    ax2.set_title(f\"√Årbol Expansi√≥n M√≠nima (Kruskal)\\n({mst_kruskal.number_of_edges()} aristas)\",\n",
        "                  fontsize=12, fontweight='bold', pad=10)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. MST PRIM\n",
        "    # ==========================================\n",
        "    ax3 = axes[2]\n",
        "\n",
        "    # Dibujar aristas\n",
        "    nx.draw_networkx_edges(\n",
        "        mst_prim, pos, ax=ax3,\n",
        "        width=3, alpha=0.8, edge_color='darkred'\n",
        "    )\n",
        "\n",
        "    # Dibujar nodos (SIN zorder)\n",
        "    nx.draw_networkx_nodes(\n",
        "        mst_prim, pos, ax=ax3, node_color='lightcoral',\n",
        "        node_size=node_size, alpha=node_alpha,\n",
        "        edgecolors='darkred', linewidths=2\n",
        "    )\n",
        "\n",
        "    # Etiquetas\n",
        "    nx.draw_networkx_labels(\n",
        "        mst_prim, pos, ax=ax3,\n",
        "        font_size=font_size, font_weight='bold'\n",
        "    )\n",
        "\n",
        "    ax3.set_title(f\"√Årbol Expansi√≥n M√≠nima (Prim)\\n({mst_prim.number_of_edges()} aristas)\",\n",
        "                  fontsize=12, fontweight='bold', pad=10)\n",
        "    ax3.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"  ‚úì Gr√°ficos para {partition_name} mostrados.\\n\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# FUNCI√ìN PRINCIPAL\n",
        "# ========================================\n",
        "\n",
        "def mostrar_grafos_de_resultados():\n",
        "    \"\"\"Genera visualizaciones para todas las particiones.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"VISUALIZACI√ìN DE GRAFOS: ORIGINAL, KRUSKAL Y PRIM\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    try:\n",
        "        # Verificar si resultados_pearson existe\n",
        "        if 'resultados_pearson' not in locals() and 'resultados_pearson' not in globals():\n",
        "             print(\"\\n‚ö†Ô∏è ERROR: La variable 'resultados_pearson' no se encontr√≥.\")\n",
        "             print(\"Por favor, ejecuta primero el script de an√°lisis de correlaci√≥n.\")\n",
        "             return\n",
        "\n",
        "        # Acceder a resultados_pearson\n",
        "        global resultados_pearson\n",
        "\n",
        "        if not resultados_pearson:\n",
        "             print(\"\\n‚ö†Ô∏è ADVERTENCIA: 'resultados_pearson' est√° vac√≠a.\")\n",
        "             return\n",
        "\n",
        "        print(f\"\\n‚úì Se encontraron {len(resultados_pearson)} particiones.\\n\")\n",
        "\n",
        "        # Iterar sobre resultados\n",
        "        for partition_name, data in resultados_pearson.items():\n",
        "\n",
        "            aristas = data.get('aristas', [])\n",
        "            threshold = data.get('threshold', 0.01)\n",
        "\n",
        "            # Obtener columnas num√©ricas\n",
        "            # Asumimos que est√°n en la partici√≥n original\n",
        "            try:\n",
        "                partition_df = particiones_analizar.get(partition_name)\n",
        "                if partition_df is None:\n",
        "                    print(f\"‚ö†Ô∏è  Saltando {partition_name}: No se encuentra en particiones_analizar\")\n",
        "                    continue\n",
        "\n",
        "                numerical_cols = []\n",
        "                for col in partition_df.columns:\n",
        "                    try:\n",
        "                        _ = float(partition_df[col].iloc[0])\n",
        "                        numerical_cols.append(col)\n",
        "                    except:\n",
        "                        pass\n",
        "            except:\n",
        "                print(f\"‚ö†Ô∏è  Saltando {partition_name}: Error obteniendo columnas num√©ricas\")\n",
        "                continue\n",
        "\n",
        "            # Visualizar\n",
        "            visualize_graphs_and_mst(aristas, numerical_cols, partition_name, threshold)\n",
        "\n",
        "        print(\"=\"*90)\n",
        "        print(\"‚úÖ VISUALIZACI√ìN DE GRAFOS COMPLETADA\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"\\n‚ùå ERROR: {e}\")\n",
        "        print(\"Aseg√∫rate de ejecutar el script de an√°lisis de correlaci√≥n primero.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error inesperado: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# Ejecutar\n",
        "mostrar_grafos_de_resultados()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6LUQx4fY1-ac"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ALGORITMO DE NEWMAN - SOLO IMPRIME RESULTADOS\n",
        "# ========================================\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "class NewmanAlgorithm:\n",
        "    \"\"\"Detecci√≥n de comunidades - Algoritmo de Newman\"\"\"\n",
        "\n",
        "    def __init__(self, grafo_nx, nombre_particion=\"\"):\n",
        "        self.grafo = grafo_nx\n",
        "        self.nombre = nombre_particion\n",
        "        self.nodos = list(grafo_nx.nodes())\n",
        "        self.n = len(self.nodos)\n",
        "        self.nodo_a_idx = {nodo: idx for idx, nodo in enumerate(self.nodos)}\n",
        "        self.idx_a_nodo = {idx: nodo for nodo, idx in self.nodo_a_idx.items()}\n",
        "\n",
        "    def _inicializar_modularidad(self):\n",
        "        \"\"\"Calcula matriz de modularidad\"\"\"\n",
        "        grados = {nodo: 0.0 for nodo in self.nodos}\n",
        "        peso_total = 0.0\n",
        "\n",
        "        for u, v, data in self.grafo.edges(data=True):\n",
        "            peso = abs(data.get('weight', 1.0))\n",
        "            peso_total += peso\n",
        "            grados[u] += peso\n",
        "            grados[v] += peso\n",
        "\n",
        "        if peso_total == 0:\n",
        "            return None, 0.0\n",
        "\n",
        "        B = {}\n",
        "        for u, v, data in self.grafo.edges(data=True):\n",
        "            peso = abs(data.get('weight', 1.0))\n",
        "            i, j = self.nodo_a_idx[u], self.nodo_a_idx[v]\n",
        "            valor_b = peso - (grados[u] * grados[v]) / (2.0 * peso_total)\n",
        "            B[(i, j)] = valor_b\n",
        "            B[(j, i)] = valor_b\n",
        "\n",
        "        return B, peso_total\n",
        "\n",
        "    def _obtener_modularidad(self, B, i, j=None):\n",
        "        if j is None:\n",
        "            return B.get((i, i), 0.0)\n",
        "        return B.get((i, j), 0.0) + B.get((j, i), 0.0)\n",
        "\n",
        "    def _calcular_Q_total(self, B, activos):\n",
        "        Q = 0.0\n",
        "        for i in activos:\n",
        "            for j in activos:\n",
        "                if i != j:\n",
        "                    Q += self._obtener_modularidad(B, i, j)\n",
        "                else:\n",
        "                    Q += B.get((i, i), 0.0)\n",
        "        return Q / 2.0\n",
        "\n",
        "    def ejecutar(self):\n",
        "        \"\"\"Ejecuta el algoritmo y retorna comunidades, Q_max, historial\"\"\"\n",
        "\n",
        "        if self.n == 0:\n",
        "            return [], 0.0, []\n",
        "\n",
        "        B, peso_total = self._inicializar_modularidad()\n",
        "\n",
        "        if B is None or not B:\n",
        "            return [[nodo] for nodo in self.nodos], 0.0, []\n",
        "\n",
        "        # Comunidades iniciales\n",
        "        comunidades = {i: {self.idx_a_nodo[i]} for i in range(self.n)}\n",
        "        a = [B.get((i, i), 0.0) for i in range(self.n)]\n",
        "        activos = set(range(self.n))\n",
        "\n",
        "        Q_inicial = self._calcular_Q_total(B, activos)\n",
        "        Q_mejor = Q_inicial\n",
        "        partition_mejor = [comunidades[i].copy() for i in activos]\n",
        "\n",
        "        historial = []\n",
        "        paso = 0\n",
        "\n",
        "        while len(activos) > 1:\n",
        "            paso += 1\n",
        "            mejor_delta_Q = float('-inf')\n",
        "            mejor_par = None\n",
        "\n",
        "            activos_lista = sorted(list(activos))\n",
        "\n",
        "            for idx_i in range(len(activos_lista)):\n",
        "                for idx_j in range(idx_i + 1, len(activos_lista)):\n",
        "                    i, j = activos_lista[idx_i], activos_lista[idx_j]\n",
        "                    delta_Q = 2.0 * (self._obtener_modularidad(B, i, j) - a[i] * a[j])\n",
        "\n",
        "                    if delta_Q > mejor_delta_Q:\n",
        "                        mejor_delta_Q = delta_Q\n",
        "                        mejor_par = (i, j)\n",
        "\n",
        "            if mejor_par is None:\n",
        "                break\n",
        "\n",
        "            i, j = mejor_par\n",
        "            Q_actual = self._calcular_Q_total(B, activos)\n",
        "            Q_nuevo = Q_actual + mejor_delta_Q\n",
        "\n",
        "            # Informaci√≥n de comunidades\n",
        "            comm_i = sorted(list(comunidades[i]))\n",
        "            comm_j = sorted(list(comunidades[j]))\n",
        "            comm_i_str = \"{\" + \", \".join(comm_i) + \"}\"\n",
        "            comm_j_str = \"{\" + \", \".join(comm_j) + \"}\"\n",
        "\n",
        "            historial.append({\n",
        "                'Paso': paso,\n",
        "                'Comunidad_A': comm_i_str,\n",
        "                'Comunidad_B': comm_j_str,\n",
        "                'Delta_Q': mejor_delta_Q,\n",
        "                'Q_anterior': Q_actual,\n",
        "                'Q_nuevo': Q_nuevo,\n",
        "                'Num_Comunidades': len(activos) - 1\n",
        "            })\n",
        "\n",
        "            # Fusionar\n",
        "            comunidades[i] = comunidades[i].union(comunidades[j])\n",
        "            del comunidades[j]\n",
        "\n",
        "            # Actualizar B\n",
        "            for col in range(self.n):\n",
        "                B[(i, col)] = B.get((i, col), 0.0) + B.get((j, col), 0.0)\n",
        "                B[(col, i)] = B.get((col, i), 0.0) + B.get((col, j), 0.0)\n",
        "\n",
        "            nuevo_diagonal = B.get((i, i), 0.0) + B.get((j, j), 0.0) + B.get((j, i), 0.0)\n",
        "            B[(i, i)] = nuevo_diagonal\n",
        "\n",
        "            for col in range(self.n):\n",
        "                B.pop((j, col), None)\n",
        "                B.pop((col, j), None)\n",
        "\n",
        "            a[i] = a[i] + a[j]\n",
        "            a[j] = 0.0\n",
        "            activos.discard(j)\n",
        "\n",
        "            if Q_nuevo > Q_mejor:\n",
        "                Q_mejor = Q_nuevo\n",
        "                partition_mejor = [comunidades[k].copy() for k in activos]\n",
        "\n",
        "        return partition_mejor, Q_mejor, historial\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# FUNCI√ìN PRINCIPAL - IMPRIME RESULTADOS\n",
        "# ========================================\n",
        "\n",
        "def ejecutar_newman_y_mostrar(df_particion, nombre_particion, threshold=0.01):\n",
        "    \"\"\"\n",
        "    Ejecuta Newman en una partici√≥n e IMPRIME todos los resultados\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*130}\")\n",
        "    print(f\"ALGORITMO DE NEWMAN - {nombre_particion.upper()}\")\n",
        "    print(f\"{'='*130}\")\n",
        "\n",
        "    # Crear grafo desde correlaciones\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Agregar nodos (todas las columnas num√©ricas)\n",
        "    cols_numericas = []\n",
        "    for col in df_particion.columns:\n",
        "        try:\n",
        "            float(df_particion[col].iloc[0])\n",
        "            cols_numericas.append(col)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    G.add_nodes_from(cols_numericas)\n",
        "\n",
        "    # Calcular correlaciones y agregar aristas\n",
        "    def calcular_correlacion(col1, col2):\n",
        "        n = len(col1)\n",
        "        media_x = sum(col1) / n\n",
        "        media_y = sum(col2) / n\n",
        "        suma_xy = sum((col1[i] - media_x) * (col2[i] - media_y) for i in range(n))\n",
        "        suma_x2 = sum((col1[i] - media_x) ** 2 for i in range(n))\n",
        "        suma_y2 = sum((col2[i] - media_y) ** 2 for i in range(n))\n",
        "        if suma_x2 == 0 or suma_y2 == 0:\n",
        "            return 0.0\n",
        "        return suma_xy / (suma_x2 * suma_y2) ** 0.5\n",
        "\n",
        "    aristas_agregadas = 0\n",
        "    for i in range(len(cols_numericas)):\n",
        "        for j in range(i + 1, len(cols_numericas)):\n",
        "            col1_vals = [float(df_particion[cols_numericas[i]].iloc[k]) for k in range(len(df_particion))]\n",
        "            col2_vals = [float(df_particion[cols_numericas[j]].iloc[k]) for k in range(len(df_particion))]\n",
        "            corr = abs(calcular_correlacion(col1_vals, col2_vals))\n",
        "\n",
        "            if corr >= threshold:\n",
        "                G.add_edge(cols_numericas[i], cols_numericas[j], weight=corr)\n",
        "                aristas_agregadas += 1\n",
        "\n",
        "    print(f\"\\nüìä INFORMACI√ìN DEL GRAFO:\")\n",
        "    print(f\"   ‚Ä¢ Nodos:       {G.number_of_nodes()}\")\n",
        "    print(f\"   ‚Ä¢ Aristas:     {G.number_of_edges()}\")\n",
        "    print(f\"   ‚Ä¢ Threshold:   {threshold}\")\n",
        "\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(f\"\\n   ‚ö†Ô∏è  Grafo vac√≠o. Sin an√°lisis posible.\")\n",
        "        return None\n",
        "\n",
        "    # Ejecutar Newman\n",
        "    print(f\"\\n{'‚îÄ'*130}\")\n",
        "    print(f\"EJECUTANDO ALGORITMO DE NEWMAN...\")\n",
        "    print(f\"{'‚îÄ'*130}\\n\")\n",
        "\n",
        "    algoritmo = NewmanAlgorithm(G, nombre_particion=nombre_particion)\n",
        "    comunidades, Q_max, historial = algoritmo.ejecutar()\n",
        "\n",
        "    # IMPRIMIR RESULTADOS INICIALES\n",
        "    print(f\"PASO 0: ESTADO INICIAL\")\n",
        "    print(f\"   ‚Ä¢ Modularidad inicial (Q):  {0.0:.8f}\")\n",
        "    print(f\"   ‚Ä¢ Comunidades:              {G.number_of_nodes()}\")\n",
        "    print(f\"   ‚Ä¢ Configuraci√≥n:            Cada nodo es su propia comunidad\\n\")\n",
        "\n",
        "    # IMPRIMIR CADA PASO\n",
        "    for paso_info in historial:\n",
        "        print(f\"PASO {paso_info['Paso']}: FUSI√ìN\")\n",
        "        print(f\"   ‚Ä¢ Fusionando: {paso_info['Comunidad_A']} + {paso_info['Comunidad_B']}\")\n",
        "        print(f\"   ‚Ä¢ ŒîQ:         {paso_info['Delta_Q']:+.8f}\")\n",
        "        print(f\"   ‚Ä¢ Q anterior: {paso_info['Q_anterior']:.8f}\")\n",
        "        print(f\"   ‚Ä¢ Q nuevo:    {paso_info['Q_nuevo']:.8f}\")\n",
        "        print(f\"   ‚Ä¢ Comunidades activas: {paso_info['Num_Comunidades']}\\n\")\n",
        "\n",
        "    # RESULTADOS FINALES\n",
        "    print(f\"{'='*130}\")\n",
        "    print(f\"‚úÖ RESULTADOS FINALES\")\n",
        "    print(f\"{'='*130}\")\n",
        "    print(f\"   ‚Ä¢ Q M√°ximo:                 {Q_max:.8f}\")\n",
        "    print(f\"   ‚Ä¢ Comunidades detectadas:   {len(comunidades)}\")\n",
        "    print(f\"   ‚Ä¢ Pasos ejecutados:         {len(historial)}\")\n",
        "    print(f\"\\nüìã COMUNIDADES DETECTADAS:\")\n",
        "\n",
        "    for idx, comunidad in enumerate(comunidades, 1):\n",
        "        nodos_sorted = sorted(list(comunidad))\n",
        "        print(f\"   [{idx}] {nodos_sorted} ({len(nodos_sorted)} variable(s))\")\n",
        "\n",
        "    print(f\"\\n{'='*130}\\n\")\n",
        "\n",
        "    return {\n",
        "        'comunidades': comunidades,\n",
        "        'Q_max': Q_max,\n",
        "        'historial': historial,\n",
        "        'num_comunidades': len(comunidades)\n",
        "    }\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# EJECUTAR EN TODAS LAS PARTICIONES\n",
        "# ========================================\n",
        "\n",
        "def ejecutar_newman_todas_particiones(particiones_lista):\n",
        "    \"\"\"\n",
        "    Ejecuta Newman en todas las particiones y IMPRIME resultados\n",
        "\n",
        "    particiones_lista: lista de tuplas [(nombre, dataframe), ...]\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\\n\" + \"üî∑\"*65)\n",
        "    print(\"APLICANDO ALGORITMO DE NEWMAN A TODAS LAS PARTICIONES\")\n",
        "    print(\"üî∑\"*65)\n",
        "\n",
        "    resultados_todos = {}\n",
        "\n",
        "    for nombre, df_part in particiones_lista:\n",
        "        resultado = ejecutar_newman_y_mostrar(df_part, nombre, threshold=0.01)\n",
        "        if resultado:\n",
        "            resultados_todos[nombre] = resultado\n",
        "\n",
        "    # TABLA COMPARATIVA FINAL\n",
        "    print(\"\\n\" + \"=\"*130)\n",
        "    print(\"TABLA COMPARATIVA: RESULTADOS POR PARTICI√ìN\")\n",
        "    print(\"=\"*130)\n",
        "    print(f\"{'Partici√≥n':<15} {'Nodos':<10} {'Aristas':<10} {'Comunidades':<15} {'Q_m√°ximo':<18} {'Pasos':<10}\")\n",
        "    print(\"‚îÄ\"*130)\n",
        "\n",
        "    for nombre, resultado in resultados_todos.items():\n",
        "        print(f\"{nombre:<15} {resultado.get('nodos', '?'):<10} {resultado.get('aristas', '?'):<10} \"\n",
        "              f\"{resultado['num_comunidades']:<15} {resultado['Q_max']:<18.8f} \"\n",
        "              f\"{len(resultado['historial']):<10}\")\n",
        "\n",
        "    print(\"=\"*130)\n",
        "\n",
        "    # AN√ÅLISIS: MEJOR Y PEOR Q\n",
        "    print(\"\\n\" + \"=\"*130)\n",
        "    print(\"AN√ÅLISIS: MEJOR Y PEOR MODULARIDAD\")\n",
        "    print(\"=\"*130)\n",
        "\n",
        "    if resultados_todos:\n",
        "        mejor_nombre = max(resultados_todos, key=lambda x: resultados_todos[x]['Q_max'])\n",
        "        peor_nombre = min(resultados_todos, key=lambda x: resultados_todos[x]['Q_max'])\n",
        "\n",
        "        mejor = resultados_todos[mejor_nombre]\n",
        "        peor = resultados_todos[peor_nombre]\n",
        "\n",
        "        print(f\"\\nü•á MEJOR Q: {mejor_nombre.upper()}\")\n",
        "        print(f\"   ‚Ä¢ Q_m√°ximo:         {mejor['Q_max']:.8f}\")\n",
        "        print(f\"   ‚Ä¢ Comunidades:      {mejor['num_comunidades']}\")\n",
        "        print(f\"   ‚Ä¢ Pasos:            {len(mejor['historial'])}\")\n",
        "\n",
        "        print(f\"\\nü•à PEOR Q: {peor_nombre.upper()}\")\n",
        "        print(f\"   ‚Ä¢ Q_m√°ximo:         {peor['Q_max']:.8f}\")\n",
        "        print(f\"   ‚Ä¢ Comunidades:      {peor['num_comunidades']}\")\n",
        "        print(f\"   ‚Ä¢ Pasos:            {len(peor['historial'])}\")\n",
        "\n",
        "        print(f\"\\nüìä DIFERENCIA: {mejor['Q_max'] - peor['Q_max']:+.8f}\")\n",
        "\n",
        "    print(\"=\"*130 + \"\\n\")\n",
        "\n",
        "    return resultados_todos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gV8BblD2Bfj"
      },
      "outputs": [],
      "source": [
        "particiones_para_newman = [\n",
        "    ('df_original', df),\n",
        "    ('B2C', B2C),\n",
        "    ('W2C', W2C),\n",
        "    ('B4C', B4C),\n",
        "    ('W4C', W4C),\n",
        "    ('B8C', B8C),\n",
        "    ('W8C', W8C),\n",
        "    ('B16C', B16C),\n",
        "    ('W16C', W16C)\n",
        "]\n",
        "\n",
        "resultados_newman = ejecutar_newman_todas_particiones(particiones_para_newman)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wZVhqngb6auk"
      },
      "outputs": [],
      "source": [
        "# =================================================================\n",
        "# PASO 6: GENERANDO √ÅRBOLES ENRAIZADOS Y PODADOS POR NIVEL\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"PASO 6: GENERANDO √ÅRBOLES ENRAIZADOS EN 'y' (PODADOS POR NIVEL)\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "# ‚≠ê PAR√ÅMETRO DE UMBRAL DE NIVEL ‚≠ê\n",
        "# Nivel 0 = 'y'\n",
        "# Nivel 1 = Hijos directos de 'y'\n",
        "# Nivel 2 = Hijos de los hijos\n",
        "LEVEL_THRESHOLD = 2\n",
        "\n",
        "print(f\"‚úì Umbral de Nivel (Profundidad) fijado en: {LEVEL_THRESHOLD}\\n\")\n",
        "\n",
        "# Verificar disponibilidad de graphviz\n",
        "layout_jerarquico_disponible = False\n",
        "try:\n",
        "    from networkx.drawing import nx_pydot\n",
        "    layout_jerarquico_disponible = True\n",
        "    print(\"‚úì Se encontr√≥ 'nx_pydot'. Usando layout jer√°rquico 'dot'.\\n\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  'nx_pydot' no disponible. Usando Shell Layout.\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# FUNCIONES DE RECORRIDO (Sin cambios)\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "def custom_bfs(graph, start_node):\n",
        "    \"\"\"Recorrido BFS desde nodo inicial.\"\"\"\n",
        "    if start_node not in graph.nodes():\n",
        "        return []\n",
        "\n",
        "    visited = set()\n",
        "    queue = deque([start_node])\n",
        "    bfs_order = []\n",
        "\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        if node not in visited:\n",
        "            visited.add(node)\n",
        "            bfs_order.append(node)\n",
        "            # Asegurarse de que el grafo tenga la funci√≥n neighbors\n",
        "            if hasattr(graph, 'neighbors'):\n",
        "                for neighbor in graph.neighbors(node):\n",
        "                    if neighbor not in visited:\n",
        "                        queue.append(neighbor)\n",
        "\n",
        "    return bfs_order\n",
        "\n",
        "def custom_dfs(graph, start_node):\n",
        "    \"\"\"Recorrido DFS desde nodo inicial.\"\"\"\n",
        "    if start_node not in graph.nodes():\n",
        "        return []\n",
        "\n",
        "    visited = set()\n",
        "    stack = [start_node]\n",
        "    dfs_order = []\n",
        "\n",
        "    while stack:\n",
        "        node = stack.pop()\n",
        "        if node not in visited:\n",
        "            visited.add(node)\n",
        "            dfs_order.append(node)\n",
        "            if hasattr(graph, 'neighbors'):\n",
        "                neighbors = list(graph.neighbors(node))\n",
        "                for neighbor in reversed(neighbors):\n",
        "                    if neighbor not in visited:\n",
        "                        stack.append(neighbor)\n",
        "\n",
        "    return dfs_order\n",
        "\n",
        "# Diccionario para almacenar resultados\n",
        "resultados_arboles = {}\n",
        "\n",
        "def crear_arbol_enraizado_particion(partition_name, mst_prim_graph, numero_paso):\n",
        "    \"\"\"\n",
        "    Crea √°rbol enraizado, lo PODA seg√∫n el LEVEL_THRESHOLD,\n",
        "    y luego ejecuta el an√°lisis (layout, viz, BFS/DFS) sobre el √°rbol podado.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*90}\")\n",
        "    print(f\"PASO {numero_paso}: PARTICI√ìN '{partition_name.upper()}'\")\n",
        "    print(f\"{'='*90}\\n\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 1. VALIDAR QUE EXISTA NODO 'y'\n",
        "    # ==========================================\n",
        "    root_node = 'y'\n",
        "    if root_node not in mst_prim_graph.nodes():\n",
        "        print(f\"  ‚úó Nodo ra√≠z '{root_node}' no encontrado. Saltando.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"1. Creando √°rbol enraizado en '{root_node}'...\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. CREAR √ÅRBOL ENRAIZADO (BFS TREE)\n",
        "    # ==========================================\n",
        "    # Primero creamos el √°rbol completo para saber todas las profundidades\n",
        "    tree_prim_y = nx.bfs_tree(mst_prim_graph, source=root_node)\n",
        "    print(f\"  ‚úì √Årbol BFS completo creado ({tree_prim_y.number_of_nodes()} nodos, {tree_prim_y.number_of_edges()} aristas)\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 2.5 APLICAR PODA POR NIVEL (THRESHOLD)\n",
        "    # ==========================================\n",
        "    print(f\"\\n2. Aplicando poda (Nivel <= {LEVEL_THRESHOLD})...\")\n",
        "\n",
        "    # 1. Encontrar todos los nodos dentro del umbral\n",
        "    nodes_to_keep = []\n",
        "    # Calculamos profundidades desde el √°rbol completo\n",
        "    heights_full = nx.shortest_path_length(tree_prim_y, source=root_node)\n",
        "\n",
        "    for node, depth in heights_full.items():\n",
        "        if depth <= LEVEL_THRESHOLD:\n",
        "            nodes_to_keep.append(node)\n",
        "\n",
        "    # 2. Crear el subgrafo basado en esos nodos\n",
        "    # Usamos .subgraph() y lo copiamos para tener un grafo independiente\n",
        "    pruned_tree = tree_prim_y.subgraph(nodes_to_keep).copy()\n",
        "\n",
        "    print(f\"  ‚úì √Årbol podado: {pruned_tree.number_of_nodes()} nodos, {pruned_tree.number_of_edges()} aristas\")\n",
        "\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. CALCULAR LAYOUT JER√ÅRQUICO (SOBRE √ÅRBOL PODADO)\n",
        "    # ==========================================\n",
        "    print(f\"\\n3. Calculando layout jer√°rquico...\")\n",
        "\n",
        "    pos = None\n",
        "    layout_name = \"Shell (Fallback)\"\n",
        "\n",
        "    # Calcular layout usando el PRUNED_TREE\n",
        "    if layout_jerarquico_disponible:\n",
        "        try:\n",
        "            pos = nx_pydot.graphviz_layout(pruned_tree, prog='dot') # <--- USA √ÅRBOL PODADO\n",
        "            layout_name = \"Jer√°rquico (dot)\"\n",
        "            print(f\"  ‚úì Layout 'dot' aplicado\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Layout 'dot' fall√≥. Usando Shell Layout.\")\n",
        "            depths = nx.shortest_path_length(pruned_tree, source=root_node) # <--- USA √ÅRBOL PODADO\n",
        "            levels = {}\n",
        "            for node, depth in depths.items():\n",
        "                if depth not in levels:\n",
        "                    levels[depth] = []\n",
        "                levels[depth].append(node)\n",
        "            shells = [levels[d] for d in sorted(levels.keys())]\n",
        "            pos = nx.shell_layout(pruned_tree, nlist=shells) # <--- USA √ÅRBOL PODADO\n",
        "            layout_name = \"Shell (Fallback)\"\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  nx_pydot no disponible. Usando Shell Layout.\")\n",
        "        depths = nx.shortest_path_length(pruned_tree, source=root_node) # <--- USA √ÅRBOL PODADO\n",
        "        levels = {}\n",
        "        for node, depth in depths.items():\n",
        "            if depth not in levels:\n",
        "                levels[depth] = []\n",
        "            levels[depth].append(node)\n",
        "        shells = [levels[d] for d in sorted(levels.keys())]\n",
        "        pos = nx.shell_layout(pruned_tree, nlist=shells) # <--- USA √ÅRBOL PODADO\n",
        "        layout_name = \"Shell (Fallback)\"\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. VISUALIZAR √ÅRBOL PODADO\n",
        "    # ==========================================\n",
        "    print(f\"\\n4. Generando visualizaci√≥n (podada)...\")\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(18, 14))\n",
        "    # T√≠tulo actualizado para reflejar la poda\n",
        "    fig.suptitle(f\"√ÅRBOL PODADO (Nivel <= {LEVEL_THRESHOLD}) EN '{root_node}' - MST PRIM\\nPartici√≥n: {partition_name.upper()}\",\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Colorear nodo ra√≠z\n",
        "    node_colors = ['#ff0000' if node == root_node else '#90EE90' for node in pruned_tree.nodes()] # <--- USA √ÅRBOL PODADO\n",
        "\n",
        "    # Dibujar √°rbol dirigido (podado)\n",
        "    nx.draw(\n",
        "        pruned_tree, # <--- USA √ÅRBOL PODADO\n",
        "        pos,\n",
        "        ax=ax,\n",
        "        with_labels=True,\n",
        "        node_size=3500,\n",
        "        node_color=node_colors,\n",
        "        edge_color='#333333',\n",
        "        width=2.5,\n",
        "        font_size=12,\n",
        "        font_weight='bold',\n",
        "        arrows=True,\n",
        "        arrowsize=30,\n",
        "        arrowstyle='-|>',\n",
        "        edgecolors='black',\n",
        "        linewidths=2.5,\n",
        "        connectionstyle='arc3,rad=0.1'\n",
        "    )\n",
        "\n",
        "    ax.set_title(f\"Layout: {layout_name} | Ra√≠z: '{root_node}'\",\n",
        "                fontsize=13, fontweight='bold', pad=15)\n",
        "    ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Guardar figura\n",
        "    filename = f\"paso_{numero_paso:02d}_{partition_name}_arbol_enraizado_PODADO.png\" # <--- Nombre actualizado\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"  ‚úì Visualizaci√≥n guardada: '{filename}'\")\n",
        "    plt.show()\n",
        "\n",
        "    # ==========================================\n",
        "    # 5. EJECUTAR BFS Y DFS (SOBRE √ÅRBOL PODADO)\n",
        "    # ==========================================\n",
        "    print(f\"\\n5. Ejecutando recorridos BFS y DFS (sobre √°rbol podado)...\")\n",
        "\n",
        "    bfs_result = custom_bfs(pruned_tree, root_node) # <--- USA √ÅRBOL PODADO\n",
        "    dfs_result = custom_dfs(pruned_tree, root_node) # <--- USA √ÅRBOL PODADO\n",
        "\n",
        "    print(f\"\\n  BFS (Amplitud):\")\n",
        "    print(f\"      {' ‚Üí '.join(bfs_result)}\")\n",
        "    print(f\"      Nodos visitados: {len(bfs_result)}\")\n",
        "\n",
        "    print(f\"\\n  DFS (Profundidad):\")\n",
        "    print(f\"      {' ‚Üí '.join(dfs_result)}\")\n",
        "    print(f\"      Nodos visitados: {len(dfs_result)}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 6. ESTAD√çSTICAS DEL √ÅRBOL (PODADO)\n",
        "    # ==========================================\n",
        "    heights = nx.shortest_path_length(pruned_tree, source=root_node) # <--- USA √ÅRBOL PODADO\n",
        "    altura = max(heights.values()) if heights else 0\n",
        "    profundidad_promedio = sum(heights.values()) / len(heights) if heights else 0\n",
        "\n",
        "    print(f\"\\n6. Estad√≠sticas del √°rbol (podado):\") # <--- T√≠tulo actualizado\n",
        "    print(f\"  ‚Ä¢ Altura (profundidad m√°xima): {altura}\")\n",
        "    print(f\"  ‚Ä¢ Profundidad promedio: {profundidad_promedio:.2f}\")\n",
        "    # Usar pruned_tree para el c√°lculo\n",
        "    branch_factor = (pruned_tree.number_of_edges() / max(1, pruned_tree.number_of_nodes() - 1)) if pruned_tree.number_of_nodes() > 1 else 0\n",
        "    print(f\"  ‚Ä¢ Factor de ramificaci√≥n: {branch_factor:.2f}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 7. GUARDAR RESULTADOS (DEL √ÅRBOL PODADO)\n",
        "    # ==========================================\n",
        "    resultados_arboles[partition_name] = {\n",
        "        'arbol_enraizado': pruned_tree, # <--- Guarda el √°rbol podado\n",
        "        'posiciones': pos,\n",
        "        'bfs': bfs_result,\n",
        "        'dfs': dfs_result,\n",
        "        'nodos_totales': pruned_tree.number_of_nodes(), # <--- Stats del podado\n",
        "        'aristas_totales': pruned_tree.number_of_edges(), # <--- Stats del podado\n",
        "        'altura': altura,\n",
        "        'profundidad_promedio': profundidad_promedio,\n",
        "        'layout': layout_name\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'‚îÄ'*90}\")\n",
        "    print(f\"‚úì Partici√≥n '{partition_name.upper()}' procesada (podada)\")\n",
        "    print(f\"{'‚îÄ'*90}\\n\")\n",
        "\n",
        "    return resultados_arboles[partition_name]\n",
        "\n",
        "# ========================================\n",
        "# EJECUTAR PARA TODAS LAS PARTICIONES\n",
        "# (Esta secci√≥n no necesita cambios,\n",
        "#  simplemente llamar√° a la funci√≥n modificada)\n",
        "# ========================================\n",
        "\n",
        "print(\"\\nObteniendo MST Prim de resultados previos...\\n\")\n",
        "\n",
        "# Usar los MST Prim ya calculados\n",
        "if 'resultados_pearson' not in globals() or 'GraphAlgorithms' not in globals():\n",
        "    print(\"‚ö†Ô∏è  ERROR: 'resultados_pearson' o 'GraphAlgorithms' no se encontr√≥.\")\n",
        "    print(\"Aseg√∫rate de ejecutar primero el an√°lisis de correlaci√≥n y visualizaci√≥n de grafos (script anterior).\")\n",
        "else:\n",
        "    particiones_lista = [\n",
        "        ('df_original', df),\n",
        "        ('B2C', B2C), ('W2C', W2C),\n",
        "        ('B4C', B4C), ('W4C', W4C),\n",
        "        ('B8C', B8C), ('W8C', W8C),\n",
        "        ('B16C', B16C), ('W16C', W16C)\n",
        "    ]\n",
        "\n",
        "    paso = 0\n",
        "    for nombre, partition_df in particiones_lista:\n",
        "        paso += 1\n",
        "        try:\n",
        "            # Obtener columnas num√©ricas\n",
        "            numerical_cols = []\n",
        "            if not partition_df.empty:\n",
        "                for col in partition_df.columns:\n",
        "                    # Usar pd.to_numeric para ser m√°s robusto\n",
        "                    if pd.to_numeric(partition_df[col], errors='coerce').notna().any():\n",
        "                         numerical_cols.append(col)\n",
        "\n",
        "            # Obtener aristas del resultado previo (si existe)\n",
        "            if nombre in resultados_pearson:\n",
        "                aristas = resultados_pearson[nombre]['aristas']\n",
        "\n",
        "                # Recrear grafo\n",
        "                G = nx.Graph()\n",
        "                G.add_nodes_from(numerical_cols)\n",
        "                if aristas:\n",
        "                    for arista in aristas:\n",
        "                        r = arista['r_pearson']\n",
        "                        weight = 1.0 - r\n",
        "                        G.add_edge(arista['var1'], arista['var2'], weight=weight, correlation=r)\n",
        "\n",
        "                # Calcular MST Prim\n",
        "                if G.number_of_edges() > 0:\n",
        "                    # Usar nuestra implementaci√≥n de Prim (del script anterior)\n",
        "                    mst_prim, _ = GraphAlgorithms.prim_mst(G)\n",
        "                    # Llamar a la funci√≥n (modificada)\n",
        "                    crear_arbol_enraizado_particion(nombre, mst_prim, paso)\n",
        "                else:\n",
        "                    print(f\"\\n{'='*90}\")\n",
        "                    print(f\"PASO {paso}: PARTICI√ìN '{nombre.upper()}'\")\n",
        "                    print(f\"{'='*90}\\n\")\n",
        "                    print(f\"‚ö†Ô∏è  Sin aristas en {nombre}. Saltando.\\n\")\n",
        "            else:\n",
        "                print(f\"\\n{'='*90}\")\n",
        "                print(f\"PASO {paso}: PARTICI√ìN '{nombre.upper()}'\")\n",
        "                print(f\"{'='*90}\\n\")\n",
        "                print(f\"‚ö†Ô∏è  {nombre} no encontrado en resultados_pearson. Saltando.\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è  Error en '{nombre}': {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            print(f\"  Continuando...\\n\")\n",
        "\n",
        "# ========================================\n",
        "# RESUMEN COMPARATIVO\n",
        "# ========================================\n",
        "\n",
        "if resultados_arboles:\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"RESUMEN COMPARATIVO DE √ÅRBOLES ENRAIZADOS (PODADOS A NIVEL <= {LEVEL_THRESHOLD})\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for partition_name, data in resultados_arboles.items():\n",
        "        print(f\"\\n{partition_name.upper()}:\")\n",
        "        print(f\"  Nodos: {data['nodos_totales']} | Aristas: {data['aristas_totales']} | Altura: {data['altura']}\")\n",
        "        print(f\"  BFS: {' ‚Üí '.join(data['bfs'])}\")\n",
        "        print(f\"  DFS: {' ‚Üí '.join(data['dfs'])}\")\n",
        "\n",
        "    # ========================================\n",
        "    # TABLA COMPARATIVA\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"TABLA COMPARATIVA DE √ÅRBOLES ENRAIZADOS (PODADOS A NIVEL <= {LEVEL_THRESHOLD})\")\n",
        "    print(\"=\"*90 + \"\\n\")\n",
        "\n",
        "    tabla_arboles = []\n",
        "    for partition_name, data in resultados_arboles.items():\n",
        "        tabla_arboles.append({\n",
        "            'Partici√≥n': partition_name,\n",
        "            'Nodos': data['nodos_totales'],\n",
        "            'Aristas': data['aristas_totales'],\n",
        "            'Altura': data['altura'],\n",
        "            'Prof_Promedio': f\"{data['profundidad_promedio']:.2f}\",\n",
        "            'Layout': data['layout']\n",
        "        })\n",
        "\n",
        "    df_arboles = pd.DataFrame(tabla_arboles)\n",
        "    print(df_arboles.to_string(index=False))\n",
        "\n",
        "    # Guardar tabla\n",
        "    df_arboles.to_csv('resumen_arboles_enraizados_podados.csv', index=False)\n",
        "    print(\"\\n‚úì Tabla guardada: 'resumen_arboles_enraizados_podados.csv'\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"‚úì GENERACI√ìN DE √ÅRBOLES PODADOS COMPLETADA\")\n",
        "    print(\"=\"*90)\n",
        "else:\n",
        "    print(\"\\nNo se generaron resultados de √°rboles enraizados.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LhopT2BxNAYu"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"VISUALIZACI√ìN: GRAFO ORIGINAL + MST KRUSKAL + MST PRIM CON CAMINOS M√ÅS LARGOS RESALTADOS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Verificar disponibilidad de pydot/graphviz\n",
        "layout_jerarquico_disponible = False\n",
        "try:\n",
        "    from networkx.drawing import nx_pydot\n",
        "    layout_jerarquico_disponible = True\n",
        "    print(\"‚úì Se encontr√≥ 'nx_pydot'. Usando layout jer√°rquico 'dot'.\\n\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  'nx_pydot' no disponible. Usando layout de resorte.\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# FUNCI√ìN AUXILIAR PARA ENCONTRAR EL CAMINO M√ÅS LARGO (DI√ÅMETRO)\n",
        "# =================================================================\n",
        "\n",
        "def encontrar_camino_mas_largo(T):\n",
        "    \"\"\"\n",
        "    Encuentra el camino m√°s largo (di√°metro) entre dos hojas en un √°rbol.\n",
        "    Devuelve el camino (lista de nodos) y su longitud (n√∫mero de aristas).\n",
        "    \"\"\"\n",
        "    if T.number_of_edges() == 0:\n",
        "        return [], 0\n",
        "\n",
        "    # Encontrar todas las hojas (nodos con grado 1)\n",
        "    leaves = [node for node in T.nodes() if T.degree(node) == 1]\n",
        "\n",
        "    # Caso especial: un grafo de 2 nodos y 1 arista (ambos son hojas)\n",
        "    if len(leaves) < 2 and T.number_of_nodes() == 2:\n",
        "        leaves = list(T.nodes())\n",
        "    elif len(leaves) < 2:\n",
        "        return [], 0\n",
        "\n",
        "    longest_path = []\n",
        "    max_len = -1\n",
        "\n",
        "    # Encontrar el camino m√°s largo entre todos los pares de hojas\n",
        "    for i in range(len(leaves)):\n",
        "        for j in range(i + 1, len(leaves)):\n",
        "            try:\n",
        "                path = nx.shortest_path(T, source=leaves[i], target=leaves[j])\n",
        "                path_len = len(path) - 1  # Longitud en aristas\n",
        "\n",
        "                if path_len > max_len:\n",
        "                    max_len = path_len\n",
        "                    longest_path = path\n",
        "            except nx.NetworkXNoPath:\n",
        "                continue\n",
        "\n",
        "    return longest_path, max_len\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# FUNCI√ìN PRINCIPAL DE VISUALIZACI√ìN\n",
        "# ========================================\n",
        "\n",
        "def visualizar_grafos_mst_particion(partition_name, aristas_filtradas, numerical_cols, numero_paso, threshold):\n",
        "    \"\"\"\n",
        "    Visualiza para una partici√≥n:\n",
        "    1. Grafo original de correlaciones\n",
        "    2. MST Kruskal con camino resaltado\n",
        "    3. MST Prim con camino resaltado\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"PASO {numero_paso}: PARTICI√ìN '{partition_name.upper()}' (threshold={threshold})\")\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 1. CREAR GRAFO ORIGINAL\n",
        "    # ==========================================\n",
        "    print(f\"1. Creando grafo de correlaciones...\")\n",
        "\n",
        "    G_temp = nx.Graph()\n",
        "    G_temp.add_nodes_from(numerical_cols)\n",
        "\n",
        "    if not aristas_filtradas:\n",
        "        print(f\"   ‚ö†Ô∏è  Sin aristas significativas. Saltando.\")\n",
        "        return\n",
        "\n",
        "    for arista in aristas_filtradas:\n",
        "        r = arista['r_pearson']\n",
        "        weight = 1.0 - r  # Para MST (busca peso m√≠nimo)\n",
        "        G_temp.add_edge(arista['var1'], arista['var2'], weight=weight, correlation=r)\n",
        "\n",
        "    print(f\"   ‚úì Grafo: {G_temp.number_of_nodes()} nodos, {G_temp.number_of_edges()} aristas\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. CALCULAR MST KRUSKAL Y PRIM\n",
        "    # ==========================================\n",
        "    print(f\"\\n2. Calculando MST Kruskal y Prim...\")\n",
        "\n",
        "    if G_temp.number_of_edges() == 0:\n",
        "        print(f\"   ‚úó Sin aristas. Saltando.\")\n",
        "        return\n",
        "\n",
        "    # MST Kruskal\n",
        "    mst_kruskal_temp = nx.minimum_spanning_tree(G_temp, weight='weight', algorithm='kruskal')\n",
        "    peso_kruskal = sum(data['weight'] for u, v, data in mst_kruskal_temp.edges(data=True))\n",
        "\n",
        "    # MST Prim\n",
        "    mst_prim_temp = nx.minimum_spanning_tree(G_temp, weight='weight', algorithm='prim')\n",
        "    peso_prim = sum(data['weight'] for u, v, data in mst_prim_temp.edges(data=True))\n",
        "\n",
        "    print(f\"   ‚úì Kruskal: {mst_kruskal_temp.number_of_nodes()} nodos, {mst_kruskal_temp.number_of_edges()} aristas, Peso: {peso_kruskal:.4f}\")\n",
        "    print(f\"   ‚úì Prim: {mst_prim_temp.number_of_nodes()} nodos, {mst_prim_temp.number_of_edges()} aristas, Peso: {peso_prim:.4f}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. ENCONTRAR CAMINOS M√ÅS LARGOS\n",
        "    # ==========================================\n",
        "    print(f\"\\n3. Encontrando caminos m√°s largos (di√°metro)...\")\n",
        "\n",
        "    path_k, len_k = encontrar_camino_mas_largo(mst_kruskal_temp)\n",
        "    print(f\"   ‚úì Kruskal - Camino m√°s largo ({len_k} aristas): {' ‚Üí '.join(path_k)}\")\n",
        "\n",
        "    path_p, len_p = encontrar_camino_mas_largo(mst_prim_temp)\n",
        "    print(f\"   ‚úì Prim - Camino m√°s largo ({len_p} aristas): {' ‚Üí '.join(path_p)}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. CALCULAR LAYOUTS\n",
        "    # ==========================================\n",
        "    print(f\"\\n4. Calculando layouts...\")\n",
        "\n",
        "    pos_original = None\n",
        "    pos_kruskal = None\n",
        "    pos_prim = None\n",
        "    layout_name = \"Spring\"\n",
        "\n",
        "    if layout_jerarquico_disponible:\n",
        "        try:\n",
        "            pos_original = nx_pydot.graphviz_layout(G_temp, prog='neato')\n",
        "            pos_kruskal = nx_pydot.graphviz_layout(mst_kruskal_temp, prog='dot')\n",
        "            pos_prim = nx_pydot.graphviz_layout(mst_prim_temp, prog='dot')\n",
        "            layout_name = \"Jer√°rquico (dot)\"\n",
        "            print(f\"   ‚úì Layout jer√°rquico aplicado\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Layout 'dot' fall√≥. Usando Spring Layout.\")\n",
        "            pos_original = nx.spring_layout(G_temp, seed=42, k=2, iterations=200)\n",
        "            pos_kruskal = nx.spring_layout(mst_kruskal_temp, seed=42, k=2, iterations=200)\n",
        "            pos_prim = nx.spring_layout(mst_prim_temp, seed=42, k=2, iterations=200)\n",
        "            layout_name = \"Spring (Fallback)\"\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  nx_pydot no disponible. Usando Spring Layout.\")\n",
        "        pos_original = nx.spring_layout(G_temp, seed=42, k=2, iterations=200)\n",
        "        pos_kruskal = nx.spring_layout(mst_kruskal_temp, seed=42, k=2, iterations=200)\n",
        "        pos_prim = nx.spring_layout(mst_prim_temp, seed=42, k=2, iterations=200)\n",
        "        layout_name = \"Spring (Fallback)\"\n",
        "\n",
        "    # ==========================================\n",
        "    # 5. CREAR VISUALIZACI√ìN 1x3\n",
        "    # ==========================================\n",
        "    print(f\"\\n5. Generando visualizaci√≥n...\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(26, 10))\n",
        "    fig.suptitle(f\"PARTICI√ìN: {partition_name.upper()} | Filas: {len(aristas_filtradas)} | Threshold: {threshold} | Layout: {layout_name}\",\n",
        "                 fontsize=17, fontweight='bold', y=0.98)\n",
        "\n",
        "    # --- GRAFO 1: ORIGINAL ---\n",
        "    ax1 = axes[0]\n",
        "\n",
        "    if G_temp.number_of_edges() > 0:\n",
        "        edge_widths_original = [abs(G_temp[u][v].get('weight', 1)) * 6 for u, v in G_temp.edges()]\n",
        "        edge_colors_original = ['#0066cc' if G_temp[u][v].get('correlation', 1) > 0 else '#ff3333'\n",
        "                                for u, v in G_temp.edges()]\n",
        "\n",
        "        nx.draw_networkx_edges(G_temp, pos_original, ax=ax1, width=edge_widths_original,\n",
        "                               edge_color=edge_colors_original, alpha=0.6)\n",
        "\n",
        "    nx.draw_networkx_nodes(G_temp, pos_original, ax=ax1, node_size=2500, node_color='lightblue',\n",
        "                           edgecolors='navy', linewidths=2.5)\n",
        "    nx.draw_networkx_labels(G_temp, pos_original, ax=ax1, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax1.set_title(f\"GRAFO ORIGINAL\\nNodos: {G_temp.number_of_nodes()} | Aristas: {G_temp.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # --- GRAFO 2: MST KRUSKAL CON CAMINO RESALTADO ---\n",
        "    ax2 = axes[1]\n",
        "\n",
        "    path_nodes_k = set(path_k)\n",
        "    other_nodes_k = set(mst_kruskal_temp.nodes()) - path_nodes_k\n",
        "\n",
        "    path_edges_k = list(zip(path_k[:-1], path_k[1:]))\n",
        "    other_edges_k = set(mst_kruskal_temp.edges())\n",
        "    for u, v in path_edges_k:\n",
        "        other_edges_k.discard((u, v))\n",
        "        other_edges_k.discard((v, u))\n",
        "\n",
        "    # Dibujar aristas normales\n",
        "    if other_edges_k:\n",
        "        nx.draw_networkx_edges(mst_kruskal_temp, pos_kruskal, ax=ax2, edgelist=other_edges_k,\n",
        "                               width=3, edge_color='#00aa00', alpha=0.6)\n",
        "\n",
        "    # Dibujar nodos normales\n",
        "    if other_nodes_k:\n",
        "        nx.draw_networkx_nodes(mst_kruskal_temp, pos_kruskal, ax=ax2, nodelist=other_nodes_k,\n",
        "                               node_size=2500, node_color='lightgreen',\n",
        "                               edgecolors='darkgreen', linewidths=2.5)\n",
        "\n",
        "    # Dibujar aristas del camino\n",
        "    if path_edges_k:\n",
        "        nx.draw_networkx_edges(mst_kruskal_temp, pos_kruskal, ax=ax2, edgelist=path_edges_k,\n",
        "                               width=7, edge_color='red', alpha=1.0, style='solid')\n",
        "\n",
        "    # Dibujar nodos del camino\n",
        "    if path_nodes_k:\n",
        "        nx.draw_networkx_nodes(mst_kruskal_temp, pos_kruskal, ax=ax2, nodelist=path_nodes_k,\n",
        "                               node_size=2800, node_color='gold',\n",
        "                               edgecolors='black', linewidths=3)\n",
        "\n",
        "    nx.draw_networkx_labels(mst_kruskal_temp, pos_kruskal, ax=ax2, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax2.set_title(f\"MST KRUSKAL (Camino m√°ximo: {len_k})\\nNodos: {mst_kruskal_temp.number_of_nodes()} | Aristas: {mst_kruskal_temp.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # --- GRAFO 3: MST PRIM CON CAMINO RESALTADO ---\n",
        "    ax3 = axes[2]\n",
        "\n",
        "    path_nodes_p = set(path_p)\n",
        "    other_nodes_p = set(mst_prim_temp.nodes()) - path_nodes_p\n",
        "\n",
        "    path_edges_p = list(zip(path_p[:-1], path_p[1:]))\n",
        "    other_edges_p = set(mst_prim_temp.edges())\n",
        "    for u, v in path_edges_p:\n",
        "        other_edges_p.discard((u, v))\n",
        "        other_edges_p.discard((v, u))\n",
        "\n",
        "    # Dibujar aristas normales\n",
        "    if other_edges_p:\n",
        "        nx.draw_networkx_edges(mst_prim_temp, pos_prim, ax=ax3, edgelist=other_edges_p,\n",
        "                               width=3, edge_color='#cc0066', alpha=0.6)\n",
        "\n",
        "    # Dibujar nodos normales\n",
        "    if other_nodes_p:\n",
        "        nx.draw_networkx_nodes(mst_prim_temp, pos_prim, ax=ax3, nodelist=other_nodes_p,\n",
        "                               node_size=2500, node_color='lightcoral',\n",
        "                               edgecolors='darkred', linewidths=2.5)\n",
        "\n",
        "    # Dibujar aristas del camino\n",
        "    if path_edges_p:\n",
        "        nx.draw_networkx_edges(mst_prim_temp, pos_prim, ax=ax3, edgelist=path_edges_p,\n",
        "                               width=7, edge_color='red', alpha=1.0, style='solid')\n",
        "\n",
        "    # Dibujar nodos del camino\n",
        "    if path_nodes_p:\n",
        "        nx.draw_networkx_nodes(mst_prim_temp, pos_prim, ax=ax3, nodelist=path_nodes_p,\n",
        "                               node_size=2800, node_color='gold',\n",
        "                               edgecolors='black', linewidths=3)\n",
        "\n",
        "    nx.draw_networkx_labels(mst_prim_temp, pos_prim, ax=ax3, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax3.set_title(f\"MST PRIM (Camino m√°ximo: {len_p})\\nNodos: {mst_prim_temp.number_of_nodes()} | Aristas: {mst_prim_temp.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax3.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"paso_{numero_paso:02d}_{partition_name}_grafos_mst_camino_resaltado.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"   ‚úì Visualizaci√≥n guardada: '{filename}'\")\n",
        "    plt.show()\n",
        "\n",
        "    # ==========================================\n",
        "    # 6. ESTAD√çSTICAS\n",
        "    # ==========================================\n",
        "    print(f\"\\n6. Estad√≠sticas:\")\n",
        "    print(f\"   {'‚îÄ'*90}\")\n",
        "\n",
        "    degree_seq = [G_temp.degree(n) for n in G_temp.nodes()]\n",
        "    print(f\"   GRAFO ORIGINAL:\")\n",
        "    print(f\"       ‚Ä¢ Densidad: {nx.density(G_temp):.4f}\")\n",
        "    print(f\"       ‚Ä¢ Grado Promedio: {sum(degree_seq)/len(degree_seq) if degree_seq else 0:.2f}\")\n",
        "    print(f\"       ‚Ä¢ Grado M√°ximo: {max(degree_seq) if degree_seq else 0}\")\n",
        "\n",
        "    print(f\"\\n   MST KRUSKAL:\")\n",
        "    print(f\"       ‚Ä¢ Peso Total: {peso_kruskal:.4f}\")\n",
        "    print(f\"       ‚Ä¢ Camino m√°s largo: {len_k} aristas\")\n",
        "\n",
        "    print(f\"\\n   MST PRIM:\")\n",
        "    print(f\"       ‚Ä¢ Peso Total: {peso_prim:.4f}\")\n",
        "    print(f\"       ‚Ä¢ Camino m√°s largo: {len_p} aristas\")\n",
        "\n",
        "    print(f\"   {'‚îÄ'*90}\\n\")\n",
        "\n",
        "    return {\n",
        "        'kruskal_camino_len': len_k,\n",
        "        'prim_camino_len': len_p,\n",
        "        'peso_kruskal': peso_kruskal,\n",
        "        'peso_prim': peso_prim\n",
        "    }\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# EJECUTAR VISUALIZACI√ìN\n",
        "# ========================================\n",
        "\n",
        "print(\"\\nObtienendo datos del an√°lisis previo...\\n\")\n",
        "\n",
        "if 'resultados_pearson' not in globals():\n",
        "    print(\"‚ö†Ô∏è  ERROR: 'resultados_pearson' no se encontr√≥.\")\n",
        "    print(\"Aseg√∫rate de ejecutar primero el an√°lisis de correlaci√≥n y visualizaci√≥n de grafos.\")\n",
        "else:\n",
        "    resultados_visualizacion = {}\n",
        "    paso = 0\n",
        "\n",
        "    for partition_name, data in resultados_pearson.items():\n",
        "        paso += 1\n",
        "\n",
        "        try:\n",
        "            aristas = data.get('aristas', [])\n",
        "            # Usar el threshold guardado en resultados_pearson, o usar el principal si no existe\n",
        "            threshold = data.get('threshold', THRESHOLD if 'THRESHOLD' in globals() else 0.75)\n",
        "\n",
        "            # Obtener columnas num√©ricas\n",
        "            if partition_name in particiones_analizar:\n",
        "                partition_df = particiones_analizar[partition_name]\n",
        "                numerical_cols = []\n",
        "                for col in partition_df.columns:\n",
        "                    try:\n",
        "                        _ = float(partition_df[col].iloc[0])\n",
        "                        numerical_cols.append(col)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Visualizar\n",
        "                resultado = visualizar_grafos_mst_particion(partition_name, aristas, numerical_cols, paso, threshold)\n",
        "                if resultado:\n",
        "                    resultados_visualizacion[partition_name] = resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è  Error en '{partition_name}': {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            print(f\"   Continuando...\\n\")\n",
        "\n",
        "    # ========================================\n",
        "    # TABLA RESUMIDA\n",
        "    # ========================================\n",
        "\n",
        "    if resultados_visualizacion:\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"TABLA RESUMIDA: CAMINOS M√ÅS LARGOS Y PESOS MST\")\n",
        "        print(\"=\"*100 + \"\\n\")\n",
        "\n",
        "        tabla_resumen = []\n",
        "        for partition_name, resultado in resultados_visualizacion.items():\n",
        "            tabla_resumen.append({\n",
        "                'Partici√≥n': partition_name,\n",
        "                'Camino_Kruskal': resultado['kruskal_camino_len'],\n",
        "                'Camino_Prim': resultado['prim_camino_len'],\n",
        "                'Peso_Kruskal': f\"{resultado['peso_kruskal']:.4f}\",\n",
        "                'Peso_Prim': f\"{resultado['peso_prim']:.4f}\"\n",
        "            })\n",
        "\n",
        "        df_resumen = pd.DataFrame(tabla_resumen)\n",
        "        print(df_resumen.to_string(index=False))\n",
        "\n",
        "        df_resumen.to_csv('resumen_caminos_mst.csv', index=False)\n",
        "        print(\"\\n‚úì Tabla guardada: 'resumen_caminos_mst.csv'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"‚úì VISUALIZACI√ìN COMPLETADA\")\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZxXl4Nu9NFX7"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"VISUALIZACI√ìN: MST PRIM (COMPLETO + CAMINO) vs MST PRIM (PODADO)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Verificar disponibilidad de pydot/graphviz\n",
        "layout_jerarquico_disponible = False\n",
        "try:\n",
        "    from networkx.drawing import nx_pydot\n",
        "    layout_jerarquico_disponible = True\n",
        "    print(\"‚úì Se encontr√≥ 'nx_pydot'. Usando layout jer√°rquico 'dot'.\\n\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  'nx_pydot' no disponible. Usando layout de resorte.\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# FUNCI√ìN AUXILIAR PARA ENCONTRAR EL CAMINO M√ÅS LARGO (DI√ÅMETRO)\n",
        "# =================================================================\n",
        "\n",
        "def encontrar_camino_mas_largo(T):\n",
        "    \"\"\"\n",
        "    Encuentra el camino m√°s largo (di√°metro) entre dos hojas en un √°rbol.\n",
        "    Devuelve el camino (lista de nodos) y su longitud (n√∫mero de aristas).\n",
        "    \"\"\"\n",
        "    if T.number_of_edges() == 0:\n",
        "        return [], 0\n",
        "\n",
        "    leaves = [node for node in T.nodes() if T.degree(node) == 1]\n",
        "\n",
        "    if len(leaves) < 2 and T.number_of_nodes() == 2:\n",
        "        leaves = list(T.nodes())\n",
        "    elif len(leaves) < 2:\n",
        "        return [], 0\n",
        "\n",
        "    longest_path = []\n",
        "    max_len = -1\n",
        "\n",
        "    for i in range(len(leaves)):\n",
        "        for j in range(i + 1, len(leaves)):\n",
        "            try:\n",
        "                path = nx.shortest_path(T, source=leaves[i], target=leaves[j])\n",
        "                path_len = len(path) - 1\n",
        "\n",
        "                if path_len > max_len:\n",
        "                    max_len = path_len\n",
        "                    longest_path = path\n",
        "            except nx.NetworkXNoPath:\n",
        "                continue\n",
        "\n",
        "    return longest_path, max_len\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# FUNCI√ìN AUXILIAR PARA PODAR EL √ÅRBOL\n",
        "# =================================================================\n",
        "\n",
        "def podar_arbol_por_la_mitad(T_original, nodo_raiz='y'):\n",
        "    \"\"\"\n",
        "    Encuentra el camino m√°s largo (di√°metro), corta el √°rbol por la mitad\n",
        "    de ese camino, y devuelve el sub-√°rbol que contiene el 'nodo_raiz'.\n",
        "    \"\"\"\n",
        "    T = T_original.copy()\n",
        "\n",
        "    if T.number_of_nodes() < 2 or T.number_of_edges() == 0:\n",
        "        return T\n",
        "\n",
        "    if nodo_raiz not in T.nodes():\n",
        "        print(f\"   ‚ö†Ô∏è  Advertencia (Poda): Nodo ra√≠z '{nodo_raiz}' no encontrado. Devolviendo MST completo.\")\n",
        "        return T\n",
        "\n",
        "    # 1. Encontrar el camino m√°s largo\n",
        "    longest_path, path_len = encontrar_camino_mas_largo(T)\n",
        "\n",
        "    if not longest_path:\n",
        "        print(f\"   ‚ö†Ô∏è  Advertencia (Poda): No se encontr√≥ ning√∫n camino. Devolviendo MST completo.\")\n",
        "        return T\n",
        "\n",
        "    if path_len <= 1:\n",
        "        print(f\"   ‚ÑπÔ∏è  Info (Poda): Camino m√°s largo ({path_len}) demasiado corto para cortar.\")\n",
        "        try:\n",
        "            componente_y = nx.node_connected_component(T, nodo_raiz)\n",
        "            return T.subgraph(componente_y).copy()\n",
        "        except Exception:\n",
        "            G_y = nx.Graph()\n",
        "            G_y.add_node(nodo_raiz)\n",
        "            return G_y\n",
        "\n",
        "    # 2. Encontrar la arista a cortar (L√≥gica Par/Impar)\n",
        "    target_edge_count = (path_len + (path_len % 2)) // 2\n",
        "\n",
        "    node_index_a = target_edge_count - 1\n",
        "    node_index_b = target_edge_count\n",
        "\n",
        "    u, v = longest_path[node_index_a], longest_path[node_index_b]\n",
        "\n",
        "    # 3. Cortar el √°rbol\n",
        "    if T.has_edge(u, v):\n",
        "        print(f\"   ‚úÇÔ∏è  Poda: Camino m√°s largo encontrado ({path_len} aristas).\")\n",
        "        print(f\"   ‚úÇÔ∏è  Poda: Cortando arista #{target_edge_count}: ({u}, {v})\")\n",
        "        T.remove_edge(u, v)\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  Advertencia (Poda): La arista a cortar ({u}, {v}) no existe. Devolviendo MST completo.\")\n",
        "        return T\n",
        "\n",
        "    # 4. Quedarse con el sub-√°rbol que contiene 'y'\n",
        "    try:\n",
        "        for component in nx.connected_components(T):\n",
        "            if nodo_raiz in component:\n",
        "                print(f\"   ‚úì Poda: Conservando componente con '{nodo_raiz}' ({len(component)} nodos).\")\n",
        "                return T.subgraph(component).copy()\n",
        "\n",
        "        print(f\"   ‚ö†Ô∏è  Advertencia (Poda): Nodo '{nodo_raiz}' qued√≥ aislado. Devolviendo solo el nodo.\")\n",
        "        G_y = nx.Graph()\n",
        "        G_y.add_node(nodo_raiz)\n",
        "        return G_y\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  Error durante la selecci√≥n de componente: {e}. Devolviendo MST completo.\")\n",
        "        return T_original\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# FUNCI√ìN PRINCIPAL DE VISUALIZACI√ìN\n",
        "# ========================================\n",
        "\n",
        "def visualizar_prim_podado_particion(partition_name, aristas_filtradas, numerical_cols, numero_paso, threshold):\n",
        "    \"\"\"\n",
        "    Visualiza para una partici√≥n:\n",
        "    1. Grafo original\n",
        "    2. MST Prim (completo con camino resaltado)\n",
        "    3. MST Prim (podado)\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"PASO {numero_paso}: PARTICI√ìN '{partition_name.upper()}' (threshold={threshold})\")\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 1. CREAR GRAFO ORIGINAL\n",
        "    # ==========================================\n",
        "    print(f\"1. Creando grafo de correlaciones...\")\n",
        "\n",
        "    G_temp = nx.Graph()\n",
        "    G_temp.add_nodes_from(numerical_cols)\n",
        "\n",
        "    if not aristas_filtradas:\n",
        "        print(f\"   ‚ö†Ô∏è  Sin aristas significativas. Saltando.\")\n",
        "        return\n",
        "\n",
        "    for arista in aristas_filtradas:\n",
        "        r = arista['r_pearson']\n",
        "        weight = 1.0 - r  # Para MST (busca peso m√≠nimo)\n",
        "        G_temp.add_edge(arista['var1'], arista['var2'], weight=weight, correlation=r)\n",
        "\n",
        "    print(f\"   ‚úì Grafo: {G_temp.number_of_nodes()} nodos, {G_temp.number_of_edges()} aristas\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. CALCULAR MST PRIM\n",
        "    # ==========================================\n",
        "    print(f\"\\n2. Calculando MST Prim...\")\n",
        "\n",
        "    if G_temp.number_of_edges() == 0:\n",
        "        print(f\"   ‚úó Sin aristas. Saltando.\")\n",
        "        return\n",
        "\n",
        "    mst_prim_temp = nx.minimum_spanning_tree(G_temp, weight='weight', algorithm='prim')\n",
        "    peso_prim = sum(data['weight'] for u, v, data in mst_prim_temp.edges(data=True))\n",
        "\n",
        "    print(f\"   ‚úì Prim: {mst_prim_temp.number_of_nodes()} nodos, {mst_prim_temp.number_of_edges()} aristas, Peso: {peso_prim:.4f}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. ENCONTRAR CAMINO M√ÅS LARGO\n",
        "    # ==========================================\n",
        "    print(f\"\\n3. Encontrando camino m√°s largo...\")\n",
        "\n",
        "    path_p, len_p = encontrar_camino_mas_largo(mst_prim_temp)\n",
        "    print(f\"   ‚úì Camino m√°s largo ({len_p} aristas): {' ‚Üí '.join(path_p)}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. PODAR EL √ÅRBOL\n",
        "    # ==========================================\n",
        "    print(f\"\\n4. Podando MST Prim...\")\n",
        "\n",
        "    mst_prim_podado = podar_arbol_por_la_mitad(mst_prim_temp, nodo_raiz='y')\n",
        "\n",
        "    # ==========================================\n",
        "    # 5. CALCULAR LAYOUTS\n",
        "    # ==========================================\n",
        "    print(f\"\\n5. Calculando layouts...\")\n",
        "\n",
        "    pos_original = None\n",
        "    pos_prim = None\n",
        "    pos_prim_podado = None\n",
        "    layout_name = \"Spring\"\n",
        "\n",
        "    if layout_jerarquico_disponible:\n",
        "        try:\n",
        "            pos_original = nx_pydot.graphviz_layout(G_temp, prog='neato')\n",
        "            pos_prim = nx_pydot.graphviz_layout(mst_prim_temp, prog='dot')\n",
        "            pos_prim_podado = nx_pydot.graphviz_layout(mst_prim_podado, prog='dot')\n",
        "            layout_name = \"Jer√°rquico (dot)\"\n",
        "            print(f\"   ‚úì Layout jer√°rquico aplicado\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Layout 'dot' fall√≥. Usando Spring Layout.\")\n",
        "            pos_original = nx.spring_layout(G_temp, seed=42, k=2, iterations=200)\n",
        "            pos_prim = nx.spring_layout(mst_prim_temp, seed=42, k=2, iterations=200)\n",
        "            pos_prim_podado = nx.spring_layout(mst_prim_podado, seed=42, k=2, iterations=200)\n",
        "            layout_name = \"Spring (Fallback)\"\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  nx_pydot no disponible. Usando Spring Layout.\")\n",
        "        pos_original = nx.spring_layout(G_temp, seed=42, k=2, iterations=200)\n",
        "        pos_prim = nx.spring_layout(mst_prim_temp, seed=42, k=2, iterations=200)\n",
        "        pos_prim_podado = nx.spring_layout(mst_prim_podado, seed=42, k=2, iterations=200)\n",
        "        layout_name = \"Spring (Fallback)\"\n",
        "\n",
        "    # ==========================================\n",
        "    # 6. CREAR VISUALIZACI√ìN 1x3\n",
        "    # ==========================================\n",
        "    print(f\"\\n6. Generando visualizaci√≥n...\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(26, 10))\n",
        "    fig.suptitle(f\"PARTICI√ìN: {partition_name.upper()} | Threshold: {threshold} | Layout: {layout_name}\",\n",
        "                 fontsize=17, fontweight='bold', y=0.98)\n",
        "\n",
        "    # --- GRAFO 1: ORIGINAL ---\n",
        "    ax1 = axes[0]\n",
        "\n",
        "    if G_temp.number_of_edges() > 0:\n",
        "        edge_widths_original = [abs(G_temp[u][v].get('weight', 1)) * 6 for u, v in G_temp.edges()]\n",
        "        edge_colors_original = ['#0066cc' if G_temp[u][v].get('correlation', 1) > 0 else '#ff3333'\n",
        "                                for u, v in G_temp.edges()]\n",
        "        nx.draw_networkx_edges(G_temp, pos_original, ax=ax1, width=edge_widths_original,\n",
        "                               edge_color=edge_colors_original, alpha=0.6)\n",
        "\n",
        "    nx.draw_networkx_nodes(G_temp, pos_original, ax=ax1, node_size=2500, node_color='lightblue',\n",
        "                           edgecolors='navy', linewidths=2.5)\n",
        "    nx.draw_networkx_labels(G_temp, pos_original, ax=ax1, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax1.set_title(f\"GRAFO ORIGINAL\\nNodos: {G_temp.number_of_nodes()} | Aristas: {G_temp.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # --- GRAFO 2: MST PRIM (COMPLETO CON CAMINO RESALTADO) ---\n",
        "    ax2 = axes[1]\n",
        "\n",
        "    path_nodes_p = set(path_p)\n",
        "    other_nodes_p = set(mst_prim_temp.nodes()) - path_nodes_p\n",
        "\n",
        "    path_edges_p = list(zip(path_p[:-1], path_p[1:]))\n",
        "    other_edges_p = set(mst_prim_temp.edges())\n",
        "    for u, v in path_edges_p:\n",
        "        other_edges_p.discard((u, v))\n",
        "        other_edges_p.discard((v, u))\n",
        "\n",
        "    # Dibujar aristas normales\n",
        "    if other_edges_p:\n",
        "        nx.draw_networkx_edges(mst_prim_temp, pos_prim, ax=ax2, edgelist=other_edges_p,\n",
        "                               width=3, edge_color='#cc0066', alpha=0.6)\n",
        "\n",
        "    # Dibujar nodos normales\n",
        "    if other_nodes_p:\n",
        "        nx.draw_networkx_nodes(mst_prim_temp, pos_prim, ax=ax2, nodelist=other_nodes_p,\n",
        "                               node_size=2500, node_color='lightcoral',\n",
        "                               edgecolors='darkred', linewidths=2.5)\n",
        "\n",
        "    # Dibujar aristas del camino\n",
        "    if path_edges_p:\n",
        "        nx.draw_networkx_edges(mst_prim_temp, pos_prim, ax=ax2, edgelist=path_edges_p,\n",
        "                               width=7, edge_color='red', alpha=1.0, style='solid')\n",
        "\n",
        "    # Dibujar nodos del camino\n",
        "    if path_nodes_p:\n",
        "        nx.draw_networkx_nodes(mst_prim_temp, pos_prim, ax=ax2, nodelist=path_nodes_p,\n",
        "                               node_size=2800, node_color='gold',\n",
        "                               edgecolors='black', linewidths=3)\n",
        "\n",
        "    nx.draw_networkx_labels(mst_prim_temp, pos_prim, ax=ax2, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax2.set_title(f\"MST PRIM (Camino m√°ximo: {len_p})\\nNodos: {mst_prim_temp.number_of_nodes()} | Aristas: {mst_prim_temp.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # --- GRAFO 3: MST PRIM (PODADO) ---\n",
        "    ax3 = axes[2]\n",
        "\n",
        "    if mst_prim_podado.number_of_edges() > 0:\n",
        "        edge_widths_podado = [abs(mst_prim_podado[u][v].get('weight', 1)) * 6 for u, v in mst_prim_podado.edges()]\n",
        "        edge_colors_podado = ['#00aa00' if mst_prim_podado[u][v].get('correlation', 1) > 0 else '#ff6600'\n",
        "                               for u, v in mst_prim_podado.edges()]\n",
        "        nx.draw_networkx_edges(mst_prim_podado, pos_prim_podado, ax=ax3, width=edge_widths_podado,\n",
        "                               edge_color=edge_colors_podado, alpha=0.85, style='solid')\n",
        "\n",
        "    nx.draw_networkx_nodes(mst_prim_podado, pos_prim_podado, ax=ax3, node_size=2500, node_color='lightgreen',\n",
        "                           edgecolors='darkgreen', linewidths=2.5)\n",
        "    nx.draw_networkx_labels(mst_prim_podado, pos_prim_podado, ax=ax3, font_size=11, font_weight='bold')\n",
        "\n",
        "    ax3.set_title(f\"MST PRIM (PODADO)\\nNodos: {mst_prim_podado.number_of_nodes()} | Aristas: {mst_prim_podado.number_of_edges()}\",\n",
        "                  fontsize=13, fontweight='bold', pad=10)\n",
        "    ax3.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"paso_{numero_paso:02d}_{partition_name}_prim_poda_comparacion.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"   ‚úì Visualizaci√≥n guardada: '{filename}'\")\n",
        "    plt.show()\n",
        "\n",
        "    # ==========================================\n",
        "    # 7. ESTAD√çSTICAS\n",
        "    # ==========================================\n",
        "    print(f\"\\n7. Estad√≠sticas:\")\n",
        "    print(f\"   {'‚îÄ'*90}\")\n",
        "\n",
        "    degree_seq = [G_temp.degree(n) for n in G_temp.nodes()]\n",
        "    print(f\"   GRAFO ORIGINAL:\")\n",
        "    print(f\"       ‚Ä¢ Densidad: {nx.density(G_temp):.4f}\")\n",
        "    print(f\"       ‚Ä¢ Grado Promedio: {sum(degree_seq)/len(degree_seq) if degree_seq else 0:.2f}\")\n",
        "\n",
        "    print(f\"\\n   MST PRIM (Original):\")\n",
        "    print(f\"       ‚Ä¢ Peso Total: {peso_prim:.4f}\")\n",
        "    print(f\"       ‚Ä¢ Camino m√°s largo: {len_p} aristas\")\n",
        "\n",
        "    print(f\"\\n   MST PRIM (Podado):\")\n",
        "    print(f\"       ‚Ä¢ Nodos restantes: {mst_prim_podado.number_of_nodes()}\")\n",
        "    print(f\"       ‚Ä¢ Aristas restantes: {mst_prim_podado.number_of_edges()}\")\n",
        "\n",
        "    print(f\"   {'‚îÄ'*90}\\n\")\n",
        "\n",
        "    return {\n",
        "        'camino_len': len_p,\n",
        "        'peso_prim': peso_prim,\n",
        "        'nodos_podado': mst_prim_podado.number_of_nodes(),\n",
        "        'aristas_podado': mst_prim_podado.number_of_edges()\n",
        "    }\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# EJECUTAR VISUALIZACI√ìN\n",
        "# ========================================\n",
        "\n",
        "print(\"\\nObtienendo datos del an√°lisis previo...\\n\")\n",
        "\n",
        "if 'resultados_pearson' not in globals():\n",
        "    print(\"‚ö†Ô∏è  ERROR: 'resultados_pearson' no se encontr√≥.\")\n",
        "    print(\"Aseg√∫rate de ejecutar primero el an√°lisis de correlaci√≥n.\")\n",
        "else:\n",
        "    resultados_poda = {}\n",
        "    paso = 0\n",
        "\n",
        "    for partition_name, data in resultados_pearson.items():\n",
        "        paso += 1\n",
        "\n",
        "        try:\n",
        "            aristas = data.get('aristas', [])\n",
        "            threshold = data.get('threshold', THRESHOLD if 'THRESHOLD' in globals() else 0.75)\n",
        "\n",
        "            # Obtener columnas num√©ricas\n",
        "            if partition_name in particiones_analizar:\n",
        "                partition_df = particiones_analizar[partition_name]\n",
        "                numerical_cols = []\n",
        "                for col in partition_df.columns:\n",
        "                    try:\n",
        "                        _ = float(partition_df[col].iloc[0])\n",
        "                        numerical_cols.append(col)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Visualizar\n",
        "                resultado = visualizar_prim_podado_particion(partition_name, aristas, numerical_cols, paso, threshold)\n",
        "                if resultado:\n",
        "                    resultados_poda[partition_name] = resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è  Error en '{partition_name}': {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            print(f\"   Continuando...\\n\")\n",
        "\n",
        "    # ========================================\n",
        "    # TABLA RESUMIDA\n",
        "    # ========================================\n",
        "\n",
        "    if resultados_poda:\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"TABLA RESUMIDA: COMPARACI√ìN PRIM ORIGINAL vs PODADO\")\n",
        "        print(\"=\"*100 + \"\\n\")\n",
        "\n",
        "        tabla_resumen = []\n",
        "        for partition_name, resultado in resultados_poda.items():\n",
        "            tabla_resumen.append({\n",
        "                'Partici√≥n': partition_name,\n",
        "                'Camino_Largo': resultado['camino_len'],\n",
        "                'Peso_Prim': f\"{resultado['peso_prim']:.4f}\",\n",
        "                'Nodos_Podado': resultado['nodos_podado'],\n",
        "                'Aristas_Podado': resultado['aristas_podado']\n",
        "            })\n",
        "\n",
        "        df_resumen = pd.DataFrame(tabla_resumen)\n",
        "        print(df_resumen.to_string(index=False))\n",
        "\n",
        "        df_resumen.to_csv('resumen_poda_prim.csv', index=False)\n",
        "        print(\"\\n‚úì Tabla guardada: 'resumen_poda_prim.csv'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"‚úì VISUALIZACI√ìN PODA COMPLETADA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kWRnq1mC1rno"
      },
      "outputs": [],
      "source": [
        "# =================================================================\n",
        "# ETAPA 4: COMPARACI√ìN GR√ÅFICA DE √ÅRBOLES PODADOS (DIFERENCIAS)\n",
        "# INTEGRADA CON ETAPA 3 - Reutiliza √°rboles ya calculados\n",
        "# =================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ETAPA 4: IDENTIFICACI√ìN DE DIFERENCIAS EN √ÅRBOLES PODADOS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# VERIFICAR DISPONIBILIDAD DE DATOS DE ETAPA 3\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "if 'mst_prim_trees' not in globals() or 'pruned_mst_trees' not in globals():\n",
        "    print(\"‚ö†Ô∏è  ADVERTENCIA: Datos de ETAPA 3 no encontrados.\")\n",
        "    print(\"   Se generar√°n los √°rboles podados localmente.\")\n",
        "    print(\"   (Aseg√∫rate de ejecutar ETAPA 3 primero para m√°xima eficiencia)\\n\")\n",
        "\n",
        "    # Si no existen, crearemos los √°rboles aqu√≠ (fallback)\n",
        "    mst_prim_trees = {}\n",
        "    pruned_mst_trees = {}\n",
        "    USAR_DATOS_ETAPA3 = False\n",
        "else:\n",
        "    print(\"‚úì Se encontraron datos de ETAPA 3.\")\n",
        "    print(f\"‚úì √Årboles MST disponibles: {list(mst_prim_trees.keys())}\")\n",
        "    print(f\"‚úì √Årboles podados disponibles: {list(pruned_mst_trees.keys())}\\n\")\n",
        "    USAR_DATOS_ETAPA3 = True\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# FUNCIONES AUXILIARES\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "def encontrar_camino_mas_largo(T):\n",
        "    \"\"\"Encuentra el camino m√°s largo (di√°metro) entre dos hojas.\"\"\"\n",
        "    if T.number_of_edges() == 0:\n",
        "        return [], 0\n",
        "\n",
        "    leaves = [node for node in T.nodes() if T.degree(node) == 1]\n",
        "    if len(leaves) < 2:\n",
        "        if T.number_of_nodes() == 1:\n",
        "            return list(T.nodes()), 0\n",
        "        elif T.number_of_nodes() == 2:\n",
        "            return list(T.nodes()), 1\n",
        "        else:\n",
        "            return [], 0\n",
        "\n",
        "    longest_path = []\n",
        "    max_len = -1\n",
        "\n",
        "    for i in range(len(leaves)):\n",
        "        for j in range(i + 1, len(leaves)):\n",
        "            try:\n",
        "                path = nx.shortest_path(T, source=leaves[i], target=leaves[j])\n",
        "                path_len = len(path) - 1\n",
        "                if path_len > max_len:\n",
        "                    max_len = path_len\n",
        "                    longest_path = path\n",
        "            except nx.NetworkXNoPath:\n",
        "                continue\n",
        "\n",
        "    return longest_path, max_len\n",
        "\n",
        "\n",
        "def podar_arbol_por_la_mitad(T_original, nodo_raiz_fijo='y'):\n",
        "    \"\"\"Corta el √°rbol por la mitad y devuelve sub-√°rbol con nodo_raiz_fijo.\"\"\"\n",
        "    T = T_original.copy()\n",
        "\n",
        "    if T.number_of_nodes() < 2 or T.number_of_edges() == 0:\n",
        "        return T\n",
        "\n",
        "    if nodo_raiz_fijo not in T.nodes():\n",
        "        if T.number_of_nodes() > 0:\n",
        "            return T.subgraph([list(T.nodes())[0]]).copy()\n",
        "        return T\n",
        "\n",
        "    longest_path, path_len = encontrar_camino_mas_largo(T)\n",
        "\n",
        "    if not longest_path or path_len <= 1:\n",
        "        try:\n",
        "            component = nx.node_connected_component(T, nodo_raiz_fijo)\n",
        "            return T.subgraph(component).copy()\n",
        "        except Exception:\n",
        "            G_y = nx.Graph()\n",
        "            G_y.add_node(nodo_raiz_fijo)\n",
        "            return G_y\n",
        "\n",
        "    target_edge_count = (path_len + (path_len % 2)) // 2\n",
        "    node_index_a = target_edge_count - 1\n",
        "    node_index_b = target_edge_count\n",
        "\n",
        "    if node_index_b >= len(longest_path):\n",
        "        return T_original.copy()\n",
        "\n",
        "    u, v = longest_path[node_index_a], longest_path[node_index_b]\n",
        "\n",
        "    if T.has_edge(u, v):\n",
        "        T.remove_edge(u, v)\n",
        "\n",
        "    try:\n",
        "        for component in nx.connected_components(T):\n",
        "            if nodo_raiz_fijo in component:\n",
        "                return T.subgraph(component).copy()\n",
        "        G_y = nx.Graph()\n",
        "        G_y.add_node(nodo_raiz_fijo)\n",
        "        return G_y\n",
        "    except Exception:\n",
        "        return T_original.copy()\n",
        "\n",
        "\n",
        "def obtener_estructura_arbol(T, root):\n",
        "    \"\"\"\n",
        "    Devuelve un diccionario {nodo: nivel_desde_raiz} para cada nodo del √°rbol.\n",
        "    \"\"\"\n",
        "    estructura = {}\n",
        "    if T.number_of_nodes() == 0:\n",
        "        return estructura\n",
        "\n",
        "    try:\n",
        "        for nodo in T.nodes():\n",
        "            try:\n",
        "                nivel = nx.shortest_path_length(T, root, nodo)\n",
        "                estructura[nodo] = nivel\n",
        "            except nx.NetworkXNoPath:\n",
        "                estructura[nodo] = None\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  Error obtener estructura: {e}\")\n",
        "\n",
        "    return estructura\n",
        "\n",
        "\n",
        "def comparar_estructuras(struct_b, struct_w, nombre_b, nombre_w):\n",
        "    \"\"\"\n",
        "    Compara las estructuras de dos √°rboles y retorna SOLO las diferencias.\n",
        "    Retorna un DataFrame con nodos que NO est√°n en la misma posici√≥n.\n",
        "    \"\"\"\n",
        "    diferencias = []\n",
        "\n",
        "    # Nodos comunes\n",
        "    nodos_comunes = set(struct_b.keys()) & set(struct_w.keys())\n",
        "\n",
        "    # Nodos solo en B\n",
        "    solo_en_b = set(struct_b.keys()) - set(struct_w.keys())\n",
        "\n",
        "    # Nodos solo en W\n",
        "    solo_en_w = set(struct_w.keys()) - set(struct_b.keys())\n",
        "\n",
        "    # 1. Diferencias en NIVEL (nodos que est√°n en ambos pero con diferente profundidad)\n",
        "    for nodo in nodos_comunes:\n",
        "        nivel_b = struct_b[nodo]\n",
        "        nivel_w = struct_w[nodo]\n",
        "\n",
        "        if nivel_b != nivel_w:  # Solo si est√°n en diferente nivel\n",
        "            diferencias.append({\n",
        "                'Tipo': 'Diferente Nivel',\n",
        "                'Nodo': nodo,\n",
        "                f'Nivel en {nombre_b}': nivel_b,\n",
        "                f'Nivel en {nombre_w}': nivel_w,\n",
        "                'Diferencia': abs(nivel_b - nivel_w) if (nivel_b is not None and nivel_w is not None) else 'N/A'\n",
        "            })\n",
        "\n",
        "    # 2. Nodos que existen solo en B\n",
        "    for nodo in solo_en_b:\n",
        "        diferencias.append({\n",
        "            'Tipo': f'Solo en {nombre_b}',\n",
        "            'Nodo': nodo,\n",
        "            f'Nivel en {nombre_b}': struct_b[nodo],\n",
        "            f'Nivel en {nombre_w}': '-',\n",
        "            'Diferencia': 'Ausente'\n",
        "        })\n",
        "\n",
        "    # 3. Nodos que existen solo en W\n",
        "    for nodo in solo_en_w:\n",
        "        diferencias.append({\n",
        "            'Tipo': f'Solo en {nombre_w}',\n",
        "            'Nodo': nodo,\n",
        "            f'Nivel en {nombre_b}': '-',\n",
        "            f'Nivel en {nombre_w}': struct_w[nodo],\n",
        "            'Diferencia': 'Ausente'\n",
        "        })\n",
        "\n",
        "    if not diferencias:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(diferencias)\n",
        "    return df.sort_values('Nodo').reset_index(drop=True)\n",
        "\n",
        "\n",
        "def visualizar_comparacion(T_b, T_w, root_b, root_w, nombre_b, nombre_w, df_diferencias):\n",
        "    \"\"\"\n",
        "    Dibuja los dos √°rboles resaltando SOLO los nodos con diferencias.\n",
        "    \"\"\"\n",
        "    print(f\"\\n   üé® Generando visualizaci√≥n comparativa...\")\n",
        "\n",
        "    nodos_b = set(T_b.nodes())\n",
        "    nodos_w = set(T_w.nodes())\n",
        "\n",
        "    # Obtener nodos con diferencias\n",
        "    if df_diferencias is not None:\n",
        "        nodos_diferentes = set(df_diferencias['Nodo'].unique())\n",
        "    else:\n",
        "        nodos_diferentes = set()\n",
        "\n",
        "    comunes = nodos_b.intersection(nodos_w) - nodos_diferentes  # Comunes SIN diferencias\n",
        "    solo_en_b = nodos_b - nodos_w\n",
        "    solo_en_w = nodos_w - nodos_b\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))\n",
        "    fig.suptitle(f\"Comparaci√≥n: {nombre_b} vs {nombre_w} | Diferencias Destacadas\",\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Layouts\n",
        "    pos_b = nx.spring_layout(T_b, seed=42, k=2, iterations=50) if T_b.number_of_nodes() > 0 else {}\n",
        "    pos_w = nx.spring_layout(T_w, seed=42, k=2, iterations=50) if T_w.number_of_nodes() > 0 else {}\n",
        "\n",
        "    # --- √Årbol B ---\n",
        "    ax1.set_title(f\"{nombre_b} ({len(nodos_b)} nodos)\", fontsize=14, fontweight='bold')\n",
        "    if pos_b:\n",
        "        # Nodos comunes (sin diferencias) - gris claro\n",
        "        if comunes:\n",
        "            nx.draw_networkx_nodes(T_b, pos_b, ax=ax1, nodelist=comunes, node_size=2000,\n",
        "                                  node_color='lightgray', edgecolors='black', linewidths=1, label='Igual posici√≥n')\n",
        "\n",
        "        # Nodos con diferencias - rojo\n",
        "        nodos_diff_b = nodos_diferentes & nodos_b\n",
        "        if nodos_diff_b:\n",
        "            nx.draw_networkx_nodes(T_b, pos_b, ax=ax1, nodelist=nodos_diff_b, node_size=2800,\n",
        "                                  node_color='#FF6B6B', edgecolors='darkred', linewidths=3, label='Diferencia detectada')\n",
        "\n",
        "        # Nodos solo en B - amarillo\n",
        "        if solo_en_b:\n",
        "            nx.draw_networkx_nodes(T_b, pos_b, ax=ax1, nodelist=solo_en_b, node_size=2800,\n",
        "                                  node_color='#FFD93D', edgecolors='#FF9F1C', linewidths=3, label=f'Solo en {nombre_b}')\n",
        "\n",
        "        # Ra√≠z - oro\n",
        "        if root_b and root_b in T_b.nodes():\n",
        "            nx.draw_networkx_nodes(T_b, pos_b, ax=ax1, nodelist=[root_b], node_size=3200,\n",
        "                                  node_color='gold', edgecolors='black', linewidths=3, label='Ra√≠z')\n",
        "\n",
        "        nx.draw_networkx_edges(T_b, pos_b, ax=ax1, edge_color='gray', width=2, alpha=0.6)\n",
        "        nx.draw_networkx_labels(T_b, pos_b, ax=ax1, font_size=9, font_weight='bold')\n",
        "        ax1.legend(loc='upper left', fontsize=10)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # --- √Årbol W ---\n",
        "    ax2.set_title(f\"{nombre_w} ({len(nodos_w)} nodos)\", fontsize=14, fontweight='bold')\n",
        "    if pos_w:\n",
        "        # Nodos comunes (sin diferencias) - gris claro\n",
        "        if comunes:\n",
        "            nx.draw_networkx_nodes(T_w, pos_w, ax=ax2, nodelist=comunes, node_size=2000,\n",
        "                                  node_color='lightgray', edgecolors='black', linewidths=1, label='Igual posici√≥n')\n",
        "\n",
        "        # Nodos con diferencias - rojo\n",
        "        nodos_diff_w = nodos_diferentes & nodos_w\n",
        "        if nodos_diff_w:\n",
        "            nx.draw_networkx_nodes(T_w, pos_w, ax=ax2, nodelist=nodos_diff_w, node_size=2800,\n",
        "                                  node_color='#FF6B6B', edgecolors='darkred', linewidths=3, label='Diferencia detectada')\n",
        "\n",
        "        # Nodos solo en W - azul\n",
        "        if solo_en_w:\n",
        "            nx.draw_networkx_nodes(T_w, pos_w, ax=ax2, nodelist=solo_en_w, node_size=2800,\n",
        "                                  node_color='#4ECDC4', edgecolors='#1A7F7E', linewidths=3, label=f'Solo en {nombre_w}')\n",
        "\n",
        "        # Ra√≠z - oro\n",
        "        if root_w and root_w in T_w.nodes():\n",
        "            nx.draw_networkx_nodes(T_w, pos_w, ax=ax2, nodelist=[root_w], node_size=3200,\n",
        "                                  node_color='gold', edgecolors='black', linewidths=3, label='Ra√≠z')\n",
        "\n",
        "        nx.draw_networkx_edges(T_w, pos_w, ax=ax2, edge_color='gray', width=2, alpha=0.6)\n",
        "        nx.draw_networkx_labels(T_w, pos_w, ax=ax2, font_size=9, font_weight='bold')\n",
        "        ax2.legend(loc='upper left', fontsize=10)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    filename = f\"comparacion_{nombre_b}_vs_{nombre_w}_diferencias.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"   ‚úì Visualizaci√≥n guardada: '{filename}'\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# PASO 1: PREPARAR √ÅRBOLES PODADOS\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(\"Preparando √°rboles podados para comparaci√≥n...\\n\")\n",
        "\n",
        "pares_a_comparar = [('B2C', 'W2C'), ('B4C', 'W4C'), ('B8C', 'W8C'), ('B16C', 'W16C')]\n",
        "todas_las_diferencias = {}\n",
        "\n",
        "if not USAR_DATOS_ETAPA3:\n",
        "    print(\"‚ö†Ô∏è  Generando √°rboles localmente (fallback)...\\n\")\n",
        "\n",
        "    if 'particiones_analizar' not in globals():\n",
        "        print(\"‚ùå ERROR: 'particiones_analizar' no disponible. Abortando.\")\n",
        "    else:\n",
        "        # Generar MSTs para pares faltantes\n",
        "        for nombre_b, nombre_w in pares_a_comparar:\n",
        "            if nombre_b not in pruned_mst_trees and nombre_b in particiones_analizar:\n",
        "                print(f\"   Generando √°rbol podado para {nombre_b}...\")\n",
        "                df_temp = particiones_analizar[nombre_b]\n",
        "                corr_matrix = df_temp.corr()\n",
        "                G_temp = nx.Graph()\n",
        "                for i in range(len(corr_matrix.columns)):\n",
        "                    for j in range(i+1, len(corr_matrix.columns)):\n",
        "                        if abs(corr_matrix.iloc[i, j]) > 0.01:\n",
        "                            G_temp.add_edge(corr_matrix.columns[i], corr_matrix.columns[j],\n",
        "                                          weight=1.0 - abs(corr_matrix.iloc[i, j]))\n",
        "\n",
        "                if G_temp.number_of_edges() > 0:\n",
        "                    mst_temp = nx.minimum_spanning_tree(G_temp, weight='weight')\n",
        "                    pruned_mst_trees[nombre_b] = podar_arbol_por_la_mitad(mst_temp, nodo_raiz_fijo='y')\n",
        "\n",
        "            if nombre_w not in pruned_mst_trees and nombre_w in particiones_analizar:\n",
        "                print(f\"   Generando √°rbol podado para {nombre_w}...\")\n",
        "                df_temp = particiones_analizar[nombre_w]\n",
        "                corr_matrix = df_temp.corr()\n",
        "                G_temp = nx.Graph()\n",
        "                for i in range(len(corr_matrix.columns)):\n",
        "                    for j in range(i+1, len(corr_matrix.columns)):\n",
        "                        if abs(corr_matrix.iloc[i, j]) > 0.01:\n",
        "                            G_temp.add_edge(corr_matrix.columns[i], corr_matrix.columns[j],\n",
        "                                          weight=1.0 - abs(corr_matrix.iloc[i, j]))\n",
        "\n",
        "                if G_temp.number_of_edges() > 0:\n",
        "                    mst_temp = nx.minimum_spanning_tree(G_temp, weight='weight')\n",
        "                    pruned_mst_trees[nombre_w] = podar_arbol_por_la_mitad(mst_temp, nodo_raiz_fijo='y')\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# PASO 2: EJECUTAR COMPARACI√ìN POR PARES\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARANDO PARES DE √ÅRBOLES PODADOS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for nombre_b, nombre_w in pares_a_comparar:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"COMPARANDO: {nombre_b} vs {nombre_w}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    try:\n",
        "        # 1. Obtener √°rboles podados\n",
        "        if nombre_b not in pruned_mst_trees or nombre_w not in pruned_mst_trees:\n",
        "            print(f\"   ‚ö†Ô∏è  √Årboles no disponibles para esta comparaci√≥n. Saltando...\")\n",
        "            continue\n",
        "\n",
        "        T_b = pruned_mst_trees[nombre_b]\n",
        "        T_w = pruned_mst_trees[nombre_w]\n",
        "\n",
        "        print(f\"   ‚úì √Årboles cargados desde ETAPA 3\")\n",
        "\n",
        "        # 2. Estad√≠sticas\n",
        "        print(f\"\\n   {nombre_b}: {T_b.number_of_nodes()} nodos, {T_b.number_of_edges()} aristas\")\n",
        "        print(f\"   {nombre_w}: {T_w.number_of_nodes()} nodos, {T_w.number_of_edges()} aristas\")\n",
        "\n",
        "        # 3. Encontrar ra√≠ces (centro del √°rbol)\n",
        "        root_b = nx.center(T_b)[0] if T_b.number_of_nodes() > 0 else None\n",
        "        root_w = nx.center(T_w)[0] if T_w.number_of_nodes() > 0 else None\n",
        "        print(f\"\\n   Ra√≠z {nombre_b}: '{root_b}'\")\n",
        "        print(f\"   Ra√≠z {nombre_w}: '{root_w}'\")\n",
        "\n",
        "        # 4. Obtener estructuras de ambos √°rboles\n",
        "        print(f\"\\n   üìä Analizando estructuras...\")\n",
        "        struct_b = obtener_estructura_arbol(T_b, root_b)\n",
        "        struct_w = obtener_estructura_arbol(T_w, root_w)\n",
        "\n",
        "        # 5. Comparar y obtener SOLO diferencias\n",
        "        df_diferencias = comparar_estructuras(struct_b, struct_w, nombre_b, nombre_w)\n",
        "\n",
        "        # 6. Mostrar resultados\n",
        "        if df_diferencias is None or len(df_diferencias) == 0:\n",
        "            print(f\"\\n   ‚úì NO HAY DIFERENCIAS - Ambos √°rboles tienen la misma estructura.\")\n",
        "        else:\n",
        "            print(f\"\\n   ‚ö†Ô∏è  DIFERENCIAS ENCONTRADAS: {len(df_diferencias)}\")\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(df_diferencias.to_string(index=False))\n",
        "            print(\"=\"*80)\n",
        "            todas_las_diferencias[f\"{nombre_b} vs {nombre_w}\"] = df_diferencias\n",
        "\n",
        "        # 7. Visualizar con diferencias resaltadas\n",
        "        visualizar_comparacion(T_b, T_w, root_b, root_w, nombre_b, nombre_w, df_diferencias)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå ERROR: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# RESUMEN FINAL\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"üìã RESUMEN DE DIFERENCIAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if todas_las_diferencias:\n",
        "    for comparacion, df_diff in todas_las_diferencias.items():\n",
        "        print(f\"\\n{comparacion}: ({len(df_diff)} diferencias)\")\n",
        "        print(\"-\" * 80)\n",
        "        print(df_diff.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n‚úì SIN DIFERENCIAS EN NINGUNA COMPARACI√ìN\")\n",
        "\n",
        "# Guardar resumen\n",
        "if todas_las_diferencias:\n",
        "    df_todas = pd.concat([df_diff.assign(Comparacion=comp)\n",
        "                          for comp, df_diff in todas_las_diferencias.items()],\n",
        "                         ignore_index=True)\n",
        "    df_todas.to_csv('resumen_diferencias_arboles.csv', index=False)\n",
        "    print(f\"\\n‚úì Resumen guardado: 'resumen_diferencias_arboles.csv'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úì AN√ÅLISIS DE DIFERENCIAS FINALIZADO\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2E4oaDeQ6YjX"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# SCRIPT 8: UNI√ìN DE RECORRIDOS POR PARES\n",
        "#\n",
        "# 1. Une BFS y DFS para 'B2C'.\n",
        "# 2. Une BFS y DFS para 'W2C'.\n",
        "# 3. Une los dos resultados (B2C y W2C)\n",
        "#    en un solo array final para \"2C\".\n",
        "# 4. Repite para 4C, 8C, 16C.\n",
        "# ========================================\n",
        "\n",
        "import traceback\n",
        "\n",
        "def _get_union_for_partition(partition_name, results_dict):\n",
        "    \"\"\"\n",
        "    Funci√≥n auxiliar para obtener la uni√≥n BFS/DFS de UNA partici√≥n.\n",
        "    Imprime los pasos intermedios.\n",
        "    \"\"\"\n",
        "    print(f\"\\n  Procesando sub-partici√≥n: {partition_name}\")\n",
        "\n",
        "    if partition_name not in results_dict:\n",
        "        print(\"    ‚ö†Ô∏è  Partici√≥n no encontrada en 'resultados_arboles'. Saltando.\")\n",
        "        return set() # Devuelve un set vac√≠o\n",
        "\n",
        "    data = results_dict[partition_name]\n",
        "    bfs_list = data.get('bfs')\n",
        "    dfs_list = data.get('dfs')\n",
        "\n",
        "    if bfs_list is None or dfs_list is None:\n",
        "        print(\"    ‚ö†Ô∏è  Datos de BFS o DFS no encontrados en esta partici√≥n. Saltando.\")\n",
        "        return set() # Devuelve un set vac√≠o\n",
        "\n",
        "    print(f\"    Recorrido BFS ({len(bfs_list)} nodos): {' ‚Üí '.join(bfs_list)}\")\n",
        "    print(f\"    Recorrido DFS ({len(dfs_list)} nodos): {' ‚Üí '.join(dfs_list)}\")\n",
        "\n",
        "    # Realizar la uni√≥n interna (BFS y DFS de esta partici√≥n)\n",
        "    union_set = set(bfs_list).union(set(dfs_list))\n",
        "    print(f\"    Sub-uni√≥n ({len(union_set)} nodos): {sorted(list(union_set))}\")\n",
        "\n",
        "    return union_set\n",
        "\n",
        "def unir_recorridos_por_pares():\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"INICIANDO SCRIPT 8: UNI√ìN DE RECORRIDOS POR PARES (B vs W)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Verificar si 'resultados_arboles' existe\n",
        "    try:\n",
        "        if 'resultados_arboles' not in locals() and 'resultados_arboles' not in globals():\n",
        "             print(\"\\n‚ö†Ô∏è ERROR: La variable 'resultados_arboles' no se encontr√≥.\")\n",
        "             print(\"Por favor, aseg√∫rate de ejecutar el 'PASO 6' (script de √°rboles enraizados) primero.\")\n",
        "             return\n",
        "\n",
        "        global resultados_arboles\n",
        "\n",
        "        if not resultados_arboles:\n",
        "             print(\"\\n‚ö†Ô∏è ADVERTENCIA: La variable 'resultados_arboles' est√° vac√≠a. Nada que procesar.\")\n",
        "             return\n",
        "\n",
        "        print(f\"\\nSe encontraron {len(resultados_arboles)} particiones en 'resultados_arboles'.\")\n",
        "\n",
        "        # 2. Definir los pares a procesar\n",
        "        pares_a_comparar = [\n",
        "            ('B2C', 'W2C'),\n",
        "            ('B4C', 'W4C'),\n",
        "            ('B8C', 'W8C'),\n",
        "            ('B16C', 'W16C')\n",
        "        ]\n",
        "\n",
        "        uniones_finales = {}\n",
        "\n",
        "        # 3. --- Procesar Pares ---\n",
        "        for nombre_b, nombre_w in pares_a_comparar:\n",
        "\n",
        "            # Obtener el nombre del par (ej: \"2C\")\n",
        "            pair_name = nombre_b[1:]\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"PROCESANDO PAR: {pair_name} (Combinando '{nombre_b}' y '{nombre_w}')\")\n",
        "            print(f\"{'='*70}\")\n",
        "\n",
        "            # 3a. Obtener la uni√≥n interna de la partici√≥n \"Best\"\n",
        "            set_b = _get_union_for_partition(nombre_b, resultados_arboles)\n",
        "\n",
        "            # 3b. Obtener la uni√≥n interna de la partici√≥n \"Worst\"\n",
        "            set_w = _get_union_for_partition(nombre_w, resultados_arboles)\n",
        "\n",
        "            # 3c. Calcular la UNI√ìN TOTAL entre B y W\n",
        "            total_union_set = set_b.union(set_w)\n",
        "            total_union_list = sorted(list(total_union_set))\n",
        "\n",
        "            uniones_finales[pair_name] = total_union_list\n",
        "\n",
        "            # 4. Imprimir el resultado final para el par\n",
        "            print(f\"\\n  --- UNI√ìN TOTAL PARA '{pair_name}' ---\")\n",
        "            print(f\"  Nodos √önicos ({len(total_union_list)}):\")\n",
        "            print(f\"  {total_union_list}\")\n",
        "\n",
        "        # 5. --- Procesar 'df_original' por separado (no tiene par) ---\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"PROCESANDO: df_original (sin par)\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        set_orig = _get_union_for_partition('df_original', resultados_arboles)\n",
        "        uniones_finales['df_original'] = sorted(list(set_orig))\n",
        "        # La funci√≥n _get_union_for_partition ya imprime el resultado,\n",
        "        # as√≠ que no necesitamos una secci√≥n de \"UNI√ìN TOTAL\".\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PROCESO DE UNI√ìN POR PARES COMPLETADO\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Opcional: puedes acceder a los resultados finales en el dict\n",
        "        # return uniones_finales\n",
        "\n",
        "    except NameError:\n",
        "        print(\"\\n‚ùå ERROR CR√çTICO: La variable 'resultados_arboles' no est√° definida.\")\n",
        "        print(\"Por favor, aseg√∫rate de ejecutar el 'PASO 6' primero.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Ocurri√≥ un error inesperado: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# --- Ejecutar la funci√≥n ---\n",
        "unir_recorridos_por_pares()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PXHan6O59Mrg"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# SCRIPT 9: EXTRAER NODOS CON DISCREPANCIAS\n",
        "#\n",
        "# Lee el diccionario 'todas_las_diferencias'\n",
        "# (generado por la Etapa 4) y extrae una\n",
        "# lista (array) de todos los nodos que\n",
        "# mostraron diferencias.\n",
        "# ========================================\n",
        "\n",
        "import traceback\n",
        "import pandas as pd\n",
        "\n",
        "def extraer_nodos_discrepantes():\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"INICIANDO SCRIPT 9: EXTRACCI√ìN DE NODOS CON DISCREPANCIAS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Verificar si 'todas_las_diferencias' existe\n",
        "    try:\n",
        "        # La variable debe existir globalmente de la celda anterior\n",
        "        if 'todas_las_diferencias' not in locals() and 'todas_las_diferencias' not in globals():\n",
        "             print(\"\\n‚ö†Ô∏è ERROR: La variable 'todas_las_diferencias' no se encontr√≥.\")\n",
        "             print(\"Por favor, aseg√∫rate de ejecutar la 'ETAPA 4' (comparaci√≥n de √°rboles) primero.\")\n",
        "             return\n",
        "\n",
        "        global todas_las_diferencias\n",
        "\n",
        "        if not todas_las_diferencias:\n",
        "             print(\"\\n‚ö†Ô∏è ADVERTENCIA: La variable 'todas_las_diferencias' est√° vac√≠a.\")\n",
        "             print(\"   (No se encontraron diferencias en la Etapa 4).\")\n",
        "             return\n",
        "\n",
        "        print(f\"\\nSe encontraron {len(todas_las_diferencias)} comparaciones en 'todas_las_diferencias'.\")\n",
        "\n",
        "        # Diccionario para guardar los arrays\n",
        "        nodos_discrepantes_por_par = {}\n",
        "\n",
        "        # 2. Iterar sobre cada par de comparaci√≥n\n",
        "        for comparacion, df_diff in todas_las_diferencias.items():\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"PROCESANDO COMPARACI√ìN: {comparacion.upper()}\")\n",
        "            print(f\"{'='*70}\")\n",
        "\n",
        "            if not isinstance(df_diff, pd.DataFrame) or 'Nodo' not in df_diff.columns:\n",
        "                print(f\"  ‚ö†Ô∏è  Datos para '{comparacion}' no son un DataFrame v√°lido o falta la columna 'Nodo'. Saltando.\")\n",
        "                continue\n",
        "\n",
        "            # --- Tarea Principal ---\n",
        "            # 1. Obtener la columna 'Nodo'\n",
        "            # 2. Usar .unique() para obtener cada nodo una sola vez\n",
        "            # 3. Convertir a una lista (array)\n",
        "            nodos_con_discrepancia = df_diff['Nodo'].unique().tolist()\n",
        "\n",
        "            # 4. Ordenar alfab√©ticamente para una salida limpia\n",
        "            nodos_con_discrepancia.sort()\n",
        "\n",
        "            # 5. Guardar el resultado\n",
        "            nodos_discrepantes_por_par[comparacion] = nodos_con_discrepancia\n",
        "\n",
        "            # 6. Imprimir el array\n",
        "            print(f\"  Total de nodos con discrepancias: {len(nodos_con_discrepancia)}\")\n",
        "            print(f\"  ARRAY DE NODOS:\")\n",
        "            print(f\"  {nodos_con_discrepancia}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"EXTRACCI√ìN DE NODOS COMPLETADA\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Puedes usar 'nodos_discrepantes_por_par' en celdas futuras\n",
        "        # return nodos_discrepantes_por_par\n",
        "\n",
        "    except NameError:\n",
        "        print(\"\\n‚ùå ERROR CR√çTICO: La variable 'todas_las_diferencias' no est√° definida.\")\n",
        "        print(\"Por favor, aseg√∫rate de ejecutar la 'ETAPA 4' primero.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Ocurri√≥ un error inesperado: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# --- Ejecutar la funci√≥n ---\n",
        "extraer_nodos_discrepantes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T8AgehZ3903f"
      },
      "outputs": [],
      "source": [
        "# ======================================================\n",
        "# SCRIPT 10: INTERSECCI√ìN DE RESULTADOS DE AN√ÅLISIS\n",
        "#\n",
        "# Compara los resultados de dos metodolog√≠as:\n",
        "# 1. (Recorridos): Nodos cercanos a 'y' (de Script 8)\n",
        "# 2. (Discrepancias): Nodos estructuralmente diferentes (de Script 9)\n",
        "#\n",
        "# Encuentra los nodos que est√°n en AMBAS listas.\n",
        "# ======================================================\n",
        "\n",
        "import traceback\n",
        "import pandas as pd\n",
        "from collections import deque # Necesario para la l√≥gica de BFS\n",
        "\n",
        "# --- PASO 1: L√≥gica de Script 8 (Uni√≥n de Recorridos) ---\n",
        "# Necesitamos la funci√≥n auxiliar de Script 8\n",
        "def _get_union_for_partition(partition_name, results_dict):\n",
        "    \"\"\"\n",
        "    Funci√≥n auxiliar para obtener la uni√≥n BFS/DFS de UNA partici√≥n.\n",
        "    (Versi√≥n silenciosa, solo devuelve el set)\n",
        "    \"\"\"\n",
        "    if partition_name not in results_dict:\n",
        "        return set() # Devuelve un set vac√≠o\n",
        "\n",
        "    data = results_dict[partition_name]\n",
        "    bfs_list = data.get('bfs')\n",
        "    dfs_list = data.get('dfs')\n",
        "\n",
        "    if bfs_list is None or dfs_list is None:\n",
        "        return set() # Devuelve un set vac√≠o\n",
        "\n",
        "    union_set = set(bfs_list).union(set(dfs_list))\n",
        "    return union_set\n",
        "\n",
        "def generar_uniones_de_recorridos(resultados_arboles):\n",
        "    \"\"\"\n",
        "    Ejecuta la l√≥gica de Script 8 para generar el dict de uniones.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- PASO 1: Generando 'Array 1' (Uni√≥n de Recorridos)... ---\")\n",
        "\n",
        "    pares_a_comparar = [\n",
        "        ('B2C', 'W2C'), ('B4C', 'W4C'),\n",
        "        ('B8C', 'W8C'), ('B16C', 'W16C')\n",
        "    ]\n",
        "    uniones_finales = {}\n",
        "\n",
        "    # Procesar Pares\n",
        "    for nombre_b, nombre_w in pares_a_comparar:\n",
        "        pair_name = nombre_b[1:] # Ej: \"2C\"\n",
        "        set_b = _get_union_for_partition(nombre_b, resultados_arboles)\n",
        "        set_w = _get_union_for_partition(nombre_w, resultados_arboles)\n",
        "\n",
        "        # Calcular la UNI√ìN TOTAL entre B y W\n",
        "        total_union_set = set_b.union(set_w)\n",
        "        uniones_finales[pair_name] = total_union_set\n",
        "\n",
        "    # Procesar 'df_original'\n",
        "    set_orig = _get_union_for_partition('df_original', resultados_arboles)\n",
        "    uniones_finales['df_original'] = set_orig\n",
        "\n",
        "    print(\"‚úì 'Array 1' (Recorridos) generado.\")\n",
        "    return uniones_finales\n",
        "\n",
        "# --- PASO 2: L√≥gica de Script 9 (Nodos Discrepantes) ---\n",
        "def generar_nodos_discrepantes(todas_las_diferencias):\n",
        "    \"\"\"\n",
        "    Ejecuta la l√≥gica de Script 9 para generar el dict de discrepancias.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- PASO 2: Generando 'Array 2' (Nodos con Discrepancias)... ---\")\n",
        "\n",
        "    nodos_discrepantes_por_par = {}\n",
        "\n",
        "    for comparacion, df_diff in todas_las_diferencias.items():\n",
        "        if not isinstance(df_diff, pd.DataFrame) or 'Nodo' not in df_diff.columns:\n",
        "            continue\n",
        "\n",
        "        # Obtener nodos √∫nicos y guardarlos como un set\n",
        "        nodos_con_discrepancia_set = set(df_diff['Nodo'].unique())\n",
        "        nodos_discrepantes_por_par[comparacion] = nodos_con_discrepancia_set\n",
        "\n",
        "    print(\"‚úì 'Array 2' (Discrepancias) generado.\")\n",
        "    return nodos_discrepantes_por_par\n",
        "\n",
        "# --- PASO 3: INTERSECCI√ìN (¬°Nuevo!) ---\n",
        "def encontrar_interseccion_final(uniones_finales, nodos_discrepantes):\n",
        "    \"\"\"\n",
        "    Compara los dos diccionarios y encuentra la intersecci√≥n.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PASO 3: REALIZANDO INTERSECCI√ìN DE RESULTADOS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Mapa para alinear los keys de los dos diccionarios\n",
        "    # Llave = (Key de Discrepancias), Valor = (Key de Recorridos)\n",
        "    key_map = {\n",
        "        'B2C vs W2C': '2C',\n",
        "        'B4C vs W4C': '4C',\n",
        "        'B8C vs W8C': '8C',\n",
        "        'B16C vs W16C': '16C'\n",
        "        # df_original no tiene discrepancias, se ignora\n",
        "    }\n",
        "\n",
        "    resultados_de_interseccion = {}\n",
        "\n",
        "    # Iteramos sobre los resultados de las Discrepancias (Array 2)\n",
        "    for comparacion_key, set_discrepantes in nodos_discrepantes.items():\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"COMPARACI√ìN: {comparacion_key.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # 1. Encontrar la key de Recorridos (Array 1)\n",
        "        if comparacion_key not in key_map:\n",
        "            print(f\"  - No se encontr√≥ un par para '{comparacion_key}' en el mapa. Saltando.\")\n",
        "            continue\n",
        "\n",
        "        recorrido_key = key_map[comparacion_key] # Ej: '2C'\n",
        "\n",
        "        # 2. Obtener los dos sets\n",
        "        set_recorridos = uniones_finales.get(recorrido_key)\n",
        "\n",
        "        if set_recorridos is None:\n",
        "            print(f\"  - No se encontraron datos de recorrido para '{recorrido_key}'. Saltando.\")\n",
        "            continue\n",
        "\n",
        "        # 3. Imprimir las dos listas de entrada\n",
        "        print(f\"  Array 1 (Recorridos {recorrido_key}):\")\n",
        "        print(f\"    {sorted(list(set_recorridos))}\")\n",
        "\n",
        "        print(f\"\\n  Array 2 (Discrepancias {comparacion_key}):\")\n",
        "        print(f\"    {sorted(list(set_discrepantes))}\")\n",
        "\n",
        "        # 4. Calcular la INTERSECCI√ìN\n",
        "        interseccion = set_recorridos.intersection(set_discrepantes)\n",
        "        lista_interseccion = sorted(list(interseccion))\n",
        "\n",
        "        resultados_de_interseccion[comparacion_key] = lista_interseccion\n",
        "\n",
        "        # 5. Imprimir el resultado final\n",
        "        print(f\"\\n  --- INTERSECCI√ìN FINAL ({len(lista_interseccion)} nodos) ---\")\n",
        "        print(f\"  (Nodos que son CERCANOS a 'y' Y ESTRUCTURALMENTE INESTABLES)\")\n",
        "        print(f\"  {lista_interseccion}\")\n",
        "\n",
        "    return resultados_de_interseccion\n",
        "\n",
        "# --- Funci√≥n Principal ---\n",
        "def ejecutar_analisis_de_interseccion():\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"INICIANDO SCRIPT 10: AN√ÅLISIS DE INTERSECCI√ìN\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Verificar dependencias\n",
        "    try:\n",
        "        if ('resultados_arboles' not in locals() and 'resultados_arboles' not in globals()) or \\\n",
        "           ('todas_las_diferencias' not in locals() and 'todas_las_diferencias' not in globals()):\n",
        "             print(\"\\n‚ö†Ô∏è ERROR: Faltan variables de scripts anteriores.\")\n",
        "             print(\"Por favor, aseg√∫rate de haber ejecutado:\")\n",
        "             print(\"  1. 'PASO 6' (para generar 'resultados_arboles')\")\n",
        "             print(\"  2. 'ETAPA 4' (para generar 'todas_las_diferencias')\")\n",
        "             return\n",
        "\n",
        "        global resultados_arboles, todas_las_diferencias\n",
        "\n",
        "        # --- PASO 1 ---\n",
        "        # (L√≥gica de Script 8)\n",
        "        uniones_finales = generar_uniones_de_recorridos(resultados_arboles)\n",
        "\n",
        "        # --- PASO 2 ---\n",
        "        # (L√≥gica de Script 9)\n",
        "        nodos_discrepantes = generar_nodos_discrepantes(todas_las_diferencias)\n",
        "\n",
        "        # --- PASO 3 ---\n",
        "        # (Nueva L√≥gica de Intersecci√≥n)\n",
        "        resultados_finales = encontrar_interseccion_final(uniones_finales, nodos_discrepantes)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SCRIPT 10: AN√ÅLISIS DE INTERSECCI√ìN COMPLETADO\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # 'resultados_finales' est√° disponible para su uso\n",
        "        # return resultados_finales\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"\\n‚ùå ERROR CR√çTICO: Faltan variables: {e}\")\n",
        "        print(\"Por favor, aseg√∫rate de ejecutar las celdas 'PASO 6' y 'ETAPA 4' primero.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Ocurri√≥ un error inesperado: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# --- Ejecutar la funci√≥n ---\n",
        "ejecutar_analisis_de_interseccion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RmQglvfTw1Ud"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# PASO FINAL: GUARDAR TODOS LOS ARCHIVOS (OPCIONAL)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO FINAL: GUARDANDO TODOS LOS RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Guardar el DataFrame original\n",
        "df.to_csv('df_original.csv', index=False)\n",
        "\n",
        "# 2. Guardar todas las particiones\n",
        "for nombre, partition_df in particiones.items():\n",
        "    if nombre != 'df_original': # Ya lo guardamos\n",
        "        filename = f'{nombre}_partition.csv'\n",
        "        partition_df.to_csv(filename, index=False)\n",
        "        print(f\"Partici√≥n guardada en '{filename}'\")\n",
        "\n",
        "# 3. Guardar las estad√≠sticas\n",
        "df_stats.to_csv('estadisticas_particiones.csv')\n",
        "print(\"Tabla de estad√≠sticas guardada en 'estadisticas_particiones.csv'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}